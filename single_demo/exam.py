#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
LangGraph Agent Demo - ç‹¬ç«‹æ¼”ç¤ºç¨‹åº
ä½¿ç”¨åŸç”Ÿ LangGraph åŒ…å®ç°ä¸€ä¸ªç®€å•çš„ Agentï¼ŒåŒ…å«è§„åˆ’å™¨å’Œå¤šä¸ªå·¥ä½œèŠ‚ç‚¹
"""

import sys
import os
from dotenv import load_dotenv
from typing import TypedDict, List, Dict, Any, Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, BaseMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import MemorySaver

# è®¾ç½®æ ‡å‡†è¾“å…¥è¾“å‡ºç¼–ç ä¸ºUTF-8
try:
    sys.stdin.reconfigure(encoding="utf-8")
    sys.stdout.reconfigure(encoding="utf-8")
    sys.stderr.reconfigure(encoding="utf-8")
except AttributeError:
    os.environ["PYTHONIOENCODING"] = "utf-8"


# ============================================================
# 1. å®šä¹‰ Agent çŠ¶æ€
# ============================================================


class AgentState(TypedDict):
    """Agent çŠ¶æ€å®šä¹‰"""

    messages: List[BaseMessage]  # å¯¹è¯æ¶ˆæ¯åˆ—è¡¨
    task_type: str  # ä»»åŠ¡ç±»å‹: math_calc, math_proof, logic, general
    plan: str  # planner åˆ¶å®šçš„è®¡åˆ’
    current_step: str  # å½“å‰æ‰§è¡Œæ­¥éª¤
    results: Dict[str, Any]  # å„èŠ‚ç‚¹çš„æ‰§è¡Œç»“æœ
    final_answer: str  # æœ€ç»ˆç­”æ¡ˆ


# ============================================================
# 2. å®šä¹‰å·¥å…·å‡½æ•°
# ============================================================


@tool
def calculator(expression: str) -> str:
    """æ‰§è¡Œæ•°å­¦è®¡ç®—

    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ "2 + 3 * 4" æˆ– "25 * 4 + 10"

    Returns:
        è®¡ç®—ç»“æœå­—ç¬¦ä¸²
    """
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šåªå…è®¸æ•°å­—å’ŒåŸºæœ¬è¿ç®—ç¬¦
        allowed_chars = set("0123456789+-*/() .")
        if not all(c in allowed_chars for c in expression):
            return f"é”™è¯¯: è¡¨è¾¾å¼åŒ…å«éæ³•å­—ç¬¦"

        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


# ============================================================
# 3. å®šä¹‰èŠ‚ç‚¹å‡½æ•°
# ============================================================

# å…¨å±€å˜é‡ï¼Œç”¨äºåœ¨èŠ‚ç‚¹ä¸­è®¿é—® LLM
llm = None


def planner_node(state: AgentState) -> AgentState:
    """è§„åˆ’å™¨èŠ‚ç‚¹ï¼šåˆ†æç”¨æˆ·è¾“å…¥ï¼Œåˆ¶å®šæ‰§è¡Œè®¡åˆ’"""
    print("\n" + "=" * 70)
    print("ğŸ¯ [PLANNER] æ­£åœ¨åˆ†æä»»åŠ¡å¹¶åˆ¶å®šè®¡åˆ’...")
    print("=" * 70)

    messages = state["messages"]
    user_input = messages[-1].content if messages else ""

    # ä½¿ç”¨ LLM åˆ†æä»»åŠ¡ç±»å‹
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡è§„åˆ’å™¨ã€‚åˆ†æç”¨æˆ·çš„é—®é¢˜ï¼Œåˆ¤æ–­ä»»åŠ¡ç±»å‹å¹¶åˆ¶å®šç®€è¦è®¡åˆ’ã€‚

ä»»åŠ¡ç±»å‹åˆ†ç±»ï¼š
- math_calc: éœ€è¦æ•°å­¦è®¡ç®—çš„é—®é¢˜ï¼ˆå¦‚ï¼šè®¡ç®—ã€æ±‚å’Œã€æ±‚ç§¯ç­‰ï¼‰
- math_proof: éœ€è¦æ•°å­¦è¯æ˜çš„é—®é¢˜ï¼ˆå¦‚ï¼šè¯æ˜å®šç†ã€æ¨å¯¼å…¬å¼ç­‰ï¼‰
- logic: éœ€è¦é€»è¾‘æ¨ç†çš„é—®é¢˜ï¼ˆå¦‚ï¼šé€»è¾‘è°œé¢˜ã€æ¨ç†é¢˜ç­‰ï¼‰
- general: ä¸€èˆ¬æ€§é—®é¢˜ï¼ˆå¦‚ï¼šè§£é‡Šæ¦‚å¿µã€å›ç­”å¸¸è¯†ç­‰ï¼‰

è¯·åˆ†æç”¨æˆ·é—®é¢˜å¹¶è¾“å‡ºï¼š
1. ä»»åŠ¡ç±»å‹ï¼ˆä»ä¸Šè¿°4ç§ä¸­é€‰æ‹©ä¸€ç§ï¼‰
2. ç®€è¦æ‰§è¡Œè®¡åˆ’ï¼ˆ1-2å¥è¯ï¼‰

æ ¼å¼å¦‚ä¸‹ï¼š
ä»»åŠ¡ç±»å‹: [ç±»å‹]
æ‰§è¡Œè®¡åˆ’: [è®¡åˆ’å†…å®¹]"""

    try:
        response = llm.invoke(
            [
                SystemMessage(content=system_prompt),
                HumanMessage(content=f"ç”¨æˆ·é—®é¢˜: {user_input}"),
            ]
        )

        plan_text = response.content

        # è§£æä»»åŠ¡ç±»å‹
        task_type = "general"
        if "math_calc" in plan_text.lower() or "è®¡ç®—" in plan_text:
            task_type = "math_calc"
        elif "math_proof" in plan_text.lower() or "è¯æ˜" in plan_text:
            task_type = "math_proof"
        elif "logic" in plan_text.lower() or "é€»è¾‘" in plan_text or "æ¨ç†" in plan_text:
            task_type = "logic"

        state["plan"] = plan_text
        state["task_type"] = task_type
        state["current_step"] = "planner"

        print(f"ğŸ“‹ ä»»åŠ¡ç±»å‹: {task_type}")
        print(f"ğŸ“‹ æ‰§è¡Œè®¡åˆ’:\n{plan_text}")
        print("=" * 70)

    except Exception as e:
        print(f"âŒ è§„åˆ’å™¨å‡ºé”™: {e}")
        state["task_type"] = "general"
        state["plan"] = "ä½¿ç”¨é»˜è®¤æµç¨‹å¤„ç†"

    return state


def math_calculator_node(state: AgentState) -> AgentState:
    """æ•°å­¦è®¡ç®—èŠ‚ç‚¹ï¼šæ‰§è¡Œæ•°å­¦è¿ç®—"""
    print("\n" + "=" * 70)
    print("ğŸ”¢ [CALCULATOR] æ‰§è¡Œæ•°å­¦è®¡ç®—...")
    print("=" * 70)

    messages = state["messages"]
    user_input = messages[-1].content if messages else ""

    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è®¡ç®—åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·çš„æ•°å­¦é—®é¢˜ï¼Œæå–éœ€è¦è®¡ç®—çš„è¡¨è¾¾å¼å¹¶æ±‚è§£ã€‚

å¦‚æœéœ€è¦è®¡ç®—ï¼Œè¯·ä½¿ç”¨ calculator å·¥å…·ã€‚
ç»™å‡ºè¯¦ç»†çš„è®¡ç®—æ­¥éª¤å’Œæœ€ç»ˆç»“æœã€‚"""

    try:
        # ç»‘å®šå·¥å…·çš„ LLM
        llm_with_tools = llm.bind_tools([calculator])
        response = llm_with_tools.invoke(
            [SystemMessage(content=system_prompt), HumanMessage(content=user_input)]
        )

        # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
        result_text = response.content
        if hasattr(response, "tool_calls") and response.tool_calls:
            # æ‰§è¡Œå·¥å…·è°ƒç”¨
            for tool_call in response.tool_calls:
                if tool_call["name"] == "calculator":
                    expr = tool_call["args"]["expression"]
                    calc_result = calculator.invoke({"expression": expr})
                    result_text = f"{result_text}\n\nå·¥å…·è°ƒç”¨: {calc_result}"

        state["results"]["calculation"] = result_text
        state["current_step"] = "math_calculator"

        print(f"âœ… è®¡ç®—ç»“æœ:\n{result_text}")
        print("=" * 70)

    except Exception as e:
        print(f"âŒ è®¡ç®—å‡ºé”™: {e}")
        state["results"]["calculation"] = f"è®¡ç®—å¤±è´¥: {str(e)}"

    return state


def math_prover_node(state: AgentState) -> AgentState:
    """æ•°å­¦è¯æ˜èŠ‚ç‚¹ï¼šè¿›è¡Œæ•°å­¦æ¨ç†å’Œè¯æ˜"""
    print("\n" + "=" * 70)
    print("ğŸ“ [PROVER] æ‰§è¡Œæ•°å­¦è¯æ˜...")
    print("=" * 70)

    messages = state["messages"]
    user_input = messages[-1].content if messages else ""

    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ•°å­¦è¯æ˜ä¸“å®¶ã€‚å¯¹ç”¨æˆ·æå‡ºçš„æ•°å­¦é—®é¢˜è¿›è¡Œä¸¥è°¨çš„æ¨ç†å’Œè¯æ˜ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼š
1. æ˜ç¡®è¦è¯æ˜çš„å‘½é¢˜
2. åˆ—å‡ºå·²çŸ¥æ¡ä»¶
3. ç»™å‡ºè¯æ˜æ­¥éª¤ï¼ˆä½¿ç”¨æ•°å­¦ç¬¦å·å’Œé€»è¾‘æ¨ç†ï¼‰
4. å¾—å‡ºç»“è®º

è¦æ±‚é€»è¾‘ä¸¥å¯†ï¼Œæ­¥éª¤æ¸…æ™°ã€‚"""

    try:
        response = llm.invoke(
            [SystemMessage(content=system_prompt), HumanMessage(content=user_input)]
        )

        proof_text = response.content
        state["results"]["proof"] = proof_text
        state["current_step"] = "math_prover"

        print(f"âœ… è¯æ˜è¿‡ç¨‹:\n{proof_text}")
        print("=" * 70)

    except Exception as e:
        print(f"âŒ è¯æ˜å‡ºé”™: {e}")
        state["results"]["proof"] = f"è¯æ˜å¤±è´¥: {str(e)}"

    return state


def logic_reasoner_node(state: AgentState) -> AgentState:
    """é€»è¾‘æ¨ç†èŠ‚ç‚¹ï¼šå¤„ç†é€»è¾‘é—®é¢˜"""
    print("\n" + "=" * 70)
    print("ğŸ§  [LOGIC] æ‰§è¡Œé€»è¾‘æ¨ç†...")
    print("=" * 70)

    messages = state["messages"]
    user_input = messages[-1].content if messages else ""

    system_prompt = """ä½ æ˜¯ä¸€ä¸ªé€»è¾‘æ¨ç†ä¸“å®¶ã€‚åˆ†æç”¨æˆ·æå‡ºçš„é€»è¾‘é—®é¢˜ï¼Œè¿›è¡Œç³»ç»Ÿçš„æ¨ç†ã€‚

è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤ï¼š
1. ç†è§£é—®é¢˜ä¸­çš„é€»è¾‘å…³ç³»
2. åˆ—å‡ºå…³é”®æ¡ä»¶å’Œçº¦æŸ
3. è¿›è¡Œé€»è¾‘æ¨å¯¼ï¼ˆå¯ä»¥ä½¿ç”¨ç¬¦å·è¡¨ç¤ºï¼‰
4. å¾—å‡ºç»“è®ºå¹¶éªŒè¯

è¦æ±‚æ¨ç†ä¸¥å¯†ï¼Œé€»è¾‘æ¸…æ™°ã€‚"""

    try:
        response = llm.invoke(
            [SystemMessage(content=system_prompt), HumanMessage(content=user_input)]
        )

        reasoning_text = response.content
        state["results"]["reasoning"] = reasoning_text
        state["current_step"] = "logic_reasoner"

        print(f"âœ… æ¨ç†è¿‡ç¨‹:\n{reasoning_text}")
        print("=" * 70)

    except Exception as e:
        print(f"âŒ æ¨ç†å‡ºé”™: {e}")
        state["results"]["reasoning"] = f"æ¨ç†å¤±è´¥: {str(e)}"

    return state


def summarizer_node(state: AgentState) -> AgentState:
    """æ€»ç»“èŠ‚ç‚¹ï¼šæ±‡æ€»æ‰€æœ‰ç»“æœå¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ"""
    print("\n" + "=" * 70)
    print("ğŸ“ [SUMMARIZER] æ€»ç»“ç»“æœ...")
    print("=" * 70)

    messages = state["messages"]
    user_input = messages[-1].content if messages else ""
    results = state.get("results", {})
    plan = state.get("plan", "")
    task_type = state.get("task_type", "general")

    # å¦‚æœæ˜¯ general ç±»å‹ï¼Œç›´æ¥å›ç­”
    if task_type == "general" or not results:
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„åŠ©æ‰‹ã€‚ç›´æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"""
        try:
            response = llm.invoke(
                [SystemMessage(content=system_prompt), HumanMessage(content=user_input)]
            )
            final_answer = response.content
        except Exception as e:
            final_answer = f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}"
    else:
        # æ±‡æ€»å„èŠ‚ç‚¹çš„ç»“æœ
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ€»ç»“åŠ©æ‰‹ã€‚æ ¹æ®ä¹‹å‰å„ä¸ªèŠ‚ç‚¹çš„æ‰§è¡Œç»“æœï¼Œç»™å‡ºæ¸…æ™°ã€å®Œæ•´çš„æœ€ç»ˆç­”æ¡ˆã€‚

è¦æ±‚ï¼š
1. ç»¼åˆæ‰€æœ‰ä¿¡æ¯
2. çªå‡ºé‡ç‚¹ç»“è®º
3. è¯­è¨€ç®€æ´æ¸…æ™°
4. å¦‚æœæœ‰è®¡ç®—ç»“æœï¼Œè¦æ˜ç¡®ç»™å‡º"""

        results_summary = "\n\n".join(
            [f"**{key}èŠ‚ç‚¹ç»“æœ:**\n{value}" for key, value in results.items()]
        )

        try:
            response = llm.invoke(
                [
                    SystemMessage(content=system_prompt),
                    HumanMessage(
                        content=f"åŸå§‹é—®é¢˜: {user_input}\n\næ‰§è¡Œè®¡åˆ’: {plan}\n\nå„èŠ‚ç‚¹ç»“æœ:\n{results_summary}\n\nè¯·ç»™å‡ºæœ€ç»ˆç­”æ¡ˆ:"
                    ),
                ]
            )
            final_answer = response.content
        except Exception as e:
            final_answer = f"æ€»ç»“å¤±è´¥ï¼Œä½†ä»¥ä¸‹æ˜¯å„èŠ‚ç‚¹çš„ç»“æœï¼š\n{results_summary}"

    state["final_answer"] = final_answer
    state["current_step"] = "summarizer"

    print(f"âœ… æœ€ç»ˆç­”æ¡ˆ:\n{final_answer}")
    print("=" * 70)

    return state


# ============================================================
# 4. å®šä¹‰è·¯ç”±å‡½æ•°
# ============================================================


def route_after_planner(
    state: AgentState,
) -> Literal["math_calculator", "math_prover", "logic_reasoner", "summarizer"]:
    """æ ¹æ®ä»»åŠ¡ç±»å‹è·¯ç”±åˆ°ä¸åŒçš„å·¥ä½œèŠ‚ç‚¹"""
    task_type = state.get("task_type", "general")

    print(f"\nğŸ”€ [ROUTER] ä»»åŠ¡ç±»å‹: {task_type}, è·¯ç”±åˆ°ç›¸åº”èŠ‚ç‚¹...")

    routing_map = {
        "math_calc": "math_calculator",
        "math_proof": "math_prover",
        "logic": "logic_reasoner",
        "general": "summarizer",
    }

    next_node = routing_map.get(task_type, "summarizer")
    print(f"ğŸ”€ [ROUTER] ä¸‹ä¸€ä¸ªèŠ‚ç‚¹: {next_node}\n")

    return next_node


# ============================================================
# 5. åˆ›å»º Agent
# ============================================================


def create_agent(config):
    """åˆ›å»º LangGraph Agent

    Args:
        config: é…ç½®å­—å…¸ï¼ŒåŒ…å« base_url å’Œ api_key

    Returns:
        ç¼–è¯‘å¥½çš„ LangGraph åº”ç”¨
    """
    global llm

    print("\nğŸ”§ æ­£åœ¨åˆå§‹åŒ– Agent...")
    print(f"ğŸ“¡ æ¨¡å‹é…ç½®:")
    print(f"   - Base URL: {config['base_url']}")
    print(f"   - Model: {config.get('model', 'deepseek-chat')}")

    # 1. åˆå§‹åŒ–æ¨¡å‹ï¼ˆåŸç”Ÿæ–¹å¼ï¼‰
    llm = ChatOpenAI(
        model=config.get("model", "deepseek-chat"),
        api_key=config["api_key"],
        base_url=config["base_url"],
        temperature=0.1,
    )

    # 2. åˆ›å»º StateGraph
    workflow = StateGraph(AgentState)

    # 3. æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("planner", planner_node)
    workflow.add_node("math_calculator", math_calculator_node)
    workflow.add_node("math_prover", math_prover_node)
    workflow.add_node("logic_reasoner", logic_reasoner_node)
    workflow.add_node("summarizer", summarizer_node)

    # 4. æ·»åŠ è¾¹ï¼ˆå®šä¹‰å·¥ä½œæµï¼‰
    # å¼€å§‹ â†’ planner
    workflow.add_edge(START, "planner")

    # planner â†’ æ¡ä»¶è·¯ç”±åˆ°å„ä¸ªå·¥ä½œèŠ‚ç‚¹
    workflow.add_conditional_edges(
        "planner",
        route_after_planner,
        {
            "math_calculator": "math_calculator",
            "math_prover": "math_prover",
            "logic_reasoner": "logic_reasoner",
            "summarizer": "summarizer",
        },
    )

    # æ‰€æœ‰å·¥ä½œèŠ‚ç‚¹ â†’ summarizer
    workflow.add_edge("math_calculator", "summarizer")
    workflow.add_edge("math_prover", "summarizer")
    workflow.add_edge("logic_reasoner", "summarizer")

    # summarizer â†’ END
    workflow.add_edge("summarizer", END)

    # 5. ç¼–è¯‘ï¼ˆå¸¦å†…å­˜ç®¡ç†ï¼‰
    app = workflow.compile(checkpointer=MemorySaver())

    print("âœ… Agent åˆå§‹åŒ–å®Œæˆï¼\n")

    return app


# ============================================================
# 6. äº¤äº’æ¨¡å¼
# ============================================================


def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("\n" + "=" * 70)
    print("ğŸ¯ LangGraph Agent Demo - äº¤äº’æ¨¡å¼")
    print("=" * 70)

    # æ¨¡å‹é…ç½®ï¼ˆå¯æ‰‹åŠ¨ä¿®æ”¹ï¼‰
    # DeepSeek åœ¨çº¿æ¨¡å‹
    load_dotenv()
    base_url = "https://api.deepseek.com"
    api_key = os.getenv("DEEPSEEK_API_KEY")

    # å¦‚æœä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„ Qwen-7Bï¼Œä¿®æ”¹ä¸ºï¼š
    # base_url = "http://localhost:8000/v1"
    # api_key = "EMPTY"

    config = {
        "base_url": base_url,
        "api_key": api_key,
        "model": "deepseek-chat",  # æˆ– "qwen-7b"
    }

    agent = create_agent(config)

    print("âœ¨ æ™ºèƒ½åŠ©æ‰‹å·²å°±ç»ªï¼è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("ğŸ’¡ æç¤ºï¼šæˆ‘å¯ä»¥å¸®ä½ è¿›è¡Œæ•°å­¦è®¡ç®—ã€æ•°å­¦è¯æ˜ã€é€»è¾‘æ¨ç†ç­‰\n")

    session_id = "interactive_session"

    while True:
        try:
            user_input = input("ğŸ’¬ ä½ : ").strip()

            if user_input.lower() in ["quit", "exit", "é€€å‡º"]:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            elif not user_input:
                continue

            # æ„å»ºåˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [HumanMessage(content=user_input)],
                "task_type": "",
                "plan": "",
                "current_step": "",
                "results": {},
                "final_answer": "",
            }

            # æ‰§è¡Œ agent
            thread_config = {"configurable": {"thread_id": session_id}}

            print("\nğŸ¤– åŠ©æ‰‹æ­£åœ¨æ€è€ƒ...")
            final_state = agent.invoke(initial_state, config=thread_config)

            # æ˜¾ç¤ºæœ€ç»ˆç­”æ¡ˆ
            print(f"\n{'='*70}")
            print("ğŸ‰ æœ€ç»ˆå›ç­”:")
            print(f"{'='*70}")
            print(final_state.get("final_answer", "æŠ±æ­‰ï¼Œæ²¡æœ‰ç”Ÿæˆç­”æ¡ˆ"))
            print(f"{'='*70}\n")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‡ºé”™äº†: {str(e)}\n")


# ============================================================
# 7. ä¸»ç¨‹åºå…¥å£
# ============================================================

if __name__ == "__main__":
    print("\n" + "=" * 70)
    print("ğŸŠ æ¬¢è¿ä½¿ç”¨ LangGraph æ™ºèƒ½åŠ©æ‰‹ Demoï¼")
    print("=" * 70)
    print("\nğŸ“š è¿™æ˜¯ä¸€ä¸ªåŸºäºåŸç”Ÿ LangGraph çš„æ¼”ç¤ºç¨‹åº")
    print("ğŸ”§ åŒ…å«ï¼šè§„åˆ’å™¨ + æ•°å­¦è®¡ç®— + æ•°å­¦è¯æ˜ + é€»è¾‘æ¨ç† + æ€»ç»“å™¨")
    print("ğŸ’» ä½¿ç”¨ langgraph-agent conda ç¯å¢ƒè¿è¡Œ\n")

    interactive_mode()
