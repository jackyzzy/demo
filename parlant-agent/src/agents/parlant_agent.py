"""
åŸºäºParlantçš„æ™ºèƒ½åŠ©æ‰‹ - ç®€åŒ–ç‰ˆæœ¬
ç›´æ¥ä½¿ç”¨æ¨¡å‹å®¢æˆ·ç«¯ï¼Œé¿å…å¤æ‚çš„server/sessionæ¶æ„
"""

import asyncio
from typing import List, Dict, Optional
import sys
import os
from dotenv import load_dotenv

# æ·»åŠ è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '../../'))
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../'))

from model_config import ModelManager, ModelProvider
from dotenv import load_dotenv

load_dotenv()


class ParlantAgent:
    """åŸºäºParlantç»“æ„çš„ç®€åŒ–æ™ºèƒ½åŠ©æ‰‹ - ç›´æ¥ä½¿ç”¨æ¨¡å‹å®¢æˆ·ç«¯"""

    def __init__(self, model_key: str = "gpt-4o"):
        """
        åˆå§‹åŒ–Parlantæ™ºèƒ½åŠ©æ‰‹

        Args:
            model_key: æ¨¡å‹é…ç½®é”®å€¼
        """
        self.model_key = model_key

        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        if not ModelManager.is_model_available(model_key):
            print(f"âŒ æ¨¡å‹ {model_key} ä¸å¯ç”¨")
            available_models = ModelManager.get_models_by_availability()
            if available_models:
                fallback_key = list(available_models.keys())[0]
                print(f"ğŸ”„ ä½¿ç”¨å›é€€æ¨¡å‹: {fallback_key}")
                self.model_key = fallback_key
            else:
                print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
                raise ValueError("æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹")

        # è·å–æ¨¡å‹é…ç½®
        self.model_config = ModelManager.get_model_config(self.model_key)

        # ä½¿ç”¨ model_factory åˆ›å»ºå®¢æˆ·ç«¯ï¼ˆä¸ LangGraph/Agno ä¿æŒä¸€è‡´ï¼‰
        from utils.model_factory import create_model_client
        self.client = create_model_client(self.model_key)

        # ä¼šè¯å†å²
        self.chat_history: Dict[str, List[Dict]] = {}

        # ç³»ç»Ÿæç¤ºè¯
        self.system_prompt = """ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€ä¸“ä¸šçš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿå¸®åŠ©ç”¨æˆ·å®Œæˆå„ç§ä»»åŠ¡ã€‚

ä½ å…·å¤‡ä»¥ä¸‹èƒ½åŠ›ï¼š
1. æœç´¢ä¿¡æ¯ï¼šå¯ä»¥ä½¿ç”¨æœç´¢å¼•æ“è·å–æœ€æ–°ä¿¡æ¯å’Œæ–°é—»
2. æ•°å­¦è®¡ç®—ï¼šå¯ä»¥è¿›è¡Œå„ç§æ•°å­¦è®¡ç®—å’Œæ•°å€¼è¿ç®—
3. è‚¡ç¥¨åˆ†æï¼šå¯ä»¥è·å–å’Œåˆ†æè‚¡ç¥¨ä¿¡æ¯
4. å¤æ‚æ¨ç†ï¼šå¯ä»¥è¿›è¡Œå¤šæ­¥æ¨ç†å’Œæ·±åº¦åˆ†æ

è¯·æ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œæ™ºèƒ½åœ°é€‰æ‹©åˆé€‚çš„å·¥å…·æ¥å¸®åŠ©å›ç­”ã€‚å§‹ç»ˆä¿æŒå‹å¥½ã€ä¸“ä¸šçš„æ€åº¦ã€‚"""

        model_info = self.model_config
        print(f"âœ… æ™ºèƒ½åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆï¼")
        print(f"ğŸ“ ä½¿ç”¨æ¨¡å‹: {self.model_key}")
        print(f"ğŸ·ï¸  æ¨¡å‹åç§°: {model_info.name}")
        print(f"ğŸ¢ æä¾›å•†: {model_info.provider.value}")
        print(f"ğŸ”§ åŠŸèƒ½: å¯¹è¯ã€æœç´¢ã€åˆ†æã€æ¨ç†ã€é‡‘èæ•°æ®")


    def _call_model(self, messages: List[Dict]) -> str:
        """
        è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›å¤

        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨

        Returns:
            str: æ¨¡å‹å›å¤
        """
        try:
            if self.model_config.provider == ModelProvider.ANTHROPIC:
                # Anthropic APIæ ¼å¼ä¸åŒ
                system_msg = messages[0]["content"] if messages[0]["role"] == "system" else self.system_prompt
                user_messages = [m for m in messages if m["role"] != "system"]

                response = self.client.messages.create(
                    model=self.model_config.model_id,
                    max_tokens=4096,
                    system=system_msg,
                    messages=user_messages
                )
                return response.content[0].text

            elif self.model_config.provider == ModelProvider.HTTP:
                # HTTPæ¨¡å‹ä½¿ç”¨ HttpModelClientï¼ˆä¸ LangGraph/Agno ä¸€è‡´ï¼‰
                response = self.client.chat_completion(
                    messages=messages,
                    temperature=0.7,
                    max_tokens=4096
                )
                return response.content

            else:
                # OpenAIå…¼å®¹APIæ ¼å¼
                response = self.client.chat.completions.create(
                    model=self.model_config.model_id,
                    messages=messages,
                    temperature=0.7,
                    max_tokens=4096
                )
                return response.choices[0].message.content

        except Exception as e:
            return f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {str(e)}"

    def chat(self, message: str, session_id: str = "default") -> str:
        """
        ä¸æ™ºèƒ½åŠ©æ‰‹å¯¹è¯

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ID

        Returns:
            str: åŠ©æ‰‹å›å¤
        """
        try:
            # åˆå§‹åŒ–ä¼šè¯å†å²
            if session_id not in self.chat_history:
                self.chat_history[session_id] = []

            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [{"role": "system", "content": self.system_prompt}]

            # æ·»åŠ å†å²æ¶ˆæ¯ï¼ˆä¿ç•™æœ€è¿‘10è½®å¯¹è¯ï¼‰
            recent_history = self.chat_history[session_id][-20:]  # 10è½® = 20æ¡æ¶ˆæ¯
            messages.extend(recent_history)

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({"role": "user", "content": message})

            # è°ƒç”¨æ¨¡å‹
            response = self._call_model(messages)

            # ä¿å­˜åˆ°å†å²
            self.chat_history[session_id].append({"role": "user", "content": message})
            self.chat_history[session_id].append({"role": "assistant", "content": response})

            return response

        except Exception as e:
            error_msg = f"å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg

    def get_chat_history(self, session_id: str = "default") -> List[str]:
        """è·å–èŠå¤©å†å²"""
        history = self.chat_history.get(session_id, [])
        formatted = []
        for msg in history:
            role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
            formatted.append(f"{role}: {msg['content'][:100]}...")
        return formatted

    def clear_history(self, session_id: str = "default"):
        """æ¸…é™¤èŠå¤©å†å²"""
        if session_id in self.chat_history:
            del self.chat_history[session_id]
        print(f"âœ… å·²æ¸…é™¤ä¼šè¯ {session_id} çš„å†å²è®°å½•")

    def switch_model(self, new_model_key: str):
        """åˆ‡æ¢æ¨¡å‹"""
        if ModelManager.is_model_available(new_model_key):
            self.model_key = new_model_key
            self.model_config = ModelManager.get_model_config(new_model_key)

            # ä½¿ç”¨ model_factory é‡æ–°åˆ›å»ºå®¢æˆ·ç«¯
            from utils.model_factory import create_model_client
            self.client = create_model_client(new_model_key)

            model_info = self.model_config
            print(f"âœ… å·²åˆ‡æ¢åˆ°æ¨¡å‹: {new_model_key}")
            print(f"ğŸ·ï¸  æ¨¡å‹åç§°: {model_info.name}")
            print(f"ğŸ¢ æä¾›å•†: {model_info.provider.value}")
        else:
            print(f"âŒ æ¨¡å‹ {new_model_key} ä¸å¯ç”¨")
            from model_config import display_available_models
            display_available_models()
