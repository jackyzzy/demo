"""
å¤šæ¨¡å‹é…ç½®ç³»ç»Ÿ
æ”¯æŒå¤šç§AIæ¨¡å‹æä¾›å•†çš„ç»Ÿä¸€é…ç½®å’Œç®¡ç†
"""

import os
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Type
from enum import Enum
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()


class ModelProvider(Enum):
    """æ¨¡å‹æä¾›å•†æšä¸¾"""

    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    GROQ = "groq"
    OLLAMA = "ollama"
    HUGGINGFACE = "huggingface"
    DEEPSEEK = "deepseek"
    HTTP = "http"


@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®æ•°æ®ç±»"""

    name: str  # æ¨¡å‹åç§°
    provider: ModelProvider  # æä¾›å•†
    model_id: str  # æ¨¡å‹ID
    api_key_env: str  # APIå¯†é’¥ç¯å¢ƒå˜é‡å
    base_url: Optional[str] = None  # åŸºç¡€URLï¼ˆå¯é€‰ï¼‰
    max_tokens: int = 4096  # æœ€å¤§tokens
    temperature: float = 0.1  # æ¸©åº¦å‚æ•°
    description: str = ""  # æè¿°
    supports_streaming: bool = True  # æ˜¯å¦æ”¯æŒæµå¼è¾“å‡º
    supports_function_calling: bool = True  # æ˜¯å¦æ”¯æŒå‡½æ•°è°ƒç”¨
    # HTTPæ¨¡å‹ç‰¹å®šé…ç½®
    vendor: Optional[str] = None  # HTTPæ¨¡å‹ä¾›åº”å•†åç§°ï¼ˆå¦‚ï¼šhuawei, alibabaç­‰ï¼‰
    headers: Optional[Dict[str, str]] = None  # é¢å¤–çš„HTTPå¤´éƒ¨
    _api_key: Optional[str] = field(default=None, init=False)  # ç¼“å­˜çš„APIå¯†é’¥

    def __post_init__(self):
        """åˆå§‹åŒ–åè‡ªåŠ¨åŠ è½½APIå¯†é’¥"""
        self._load_api_key()

    def _load_api_key(self):
        """ä»ç¯å¢ƒå˜é‡åŠ è½½APIå¯†é’¥"""
        if self.api_key_env:
            self._api_key = os.getenv(self.api_key_env)

    @property
    def api_key(self) -> Optional[str]:
        """è·å–APIå¯†é’¥"""
        if self._api_key is None and self.api_key_env:
            self._load_api_key()
        return self._api_key

    @property
    def is_available(self) -> bool:
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨ï¼ˆæœ‰APIå¯†é’¥æˆ–ä¸éœ€è¦APIå¯†é’¥ï¼‰"""
        # Ollamaæœ¬åœ°æ¨¡å‹ä¸éœ€è¦APIå¯†é’¥
        if self.provider == ModelProvider.OLLAMA:
            return True

        # å…¶ä»–æ¨¡å‹éœ€è¦APIå¯†é’¥
        if not self.api_key_env:
            # å¦‚æœæ²¡æœ‰å®šä¹‰APIå¯†é’¥ç¯å¢ƒå˜é‡åï¼Œåˆ™è®¤ä¸ºä¸éœ€è¦APIå¯†é’¥
            return True

        # æ£€æŸ¥APIå¯†é’¥æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
        if not self.api_key or not self.api_key.strip():
            return False

        # éªŒè¯APIå¯†é’¥æ ¼å¼
        return self._validate_api_key_format()

    def _validate_api_key_format(self) -> bool:
        """éªŒè¯APIå¯†é’¥æ ¼å¼æ˜¯å¦æ­£ç¡®"""
        if not self.api_key:
            return False

        api_key = self.api_key.strip()

        # æ£€æŸ¥æ˜¯å¦æ˜¯å ä½ç¬¦
        placeholder_patterns = [
            "sk-your-openai-key-here",
            "sk-your-api-key-here",
            "your-api-key-here",
            "gsk-your-groq-key-here",
            "hf_your-huggingface-key-here",
            "tvly-your-tavily-key-here",
            "sk-your-***********here",
            "xxxxxx",
        ]
        if api_key in placeholder_patterns:
            return False

        # æ ¹æ®æä¾›å•†éªŒè¯APIå¯†é’¥æ ¼å¼
        if self.provider == ModelProvider.OPENAI:
            # OpenAI APIå¯†é’¥é€šå¸¸ä»¥sk-å¼€å¤´ï¼Œé•¿åº¦çº¦ä¸º51ä¸ªå­—ç¬¦
            return api_key.startswith("sk-") and len(api_key) > 20

        elif self.provider == ModelProvider.ANTHROPIC:
            # Anthropic APIå¯†é’¥é€šå¸¸ä»¥sk-ant-å¼€å¤´
            return api_key.startswith("sk-ant-") and len(api_key) > 20

        elif self.provider == ModelProvider.GROQ:
            # Groq APIå¯†é’¥é€šå¸¸ä»¥gsk-å¼€å¤´
            return api_key.startswith("gsk-") and len(api_key) > 20

        elif self.provider == ModelProvider.DEEPSEEK:
            # DeepSeek APIå¯†é’¥é€šå¸¸ä»¥sk-å¼€å¤´ï¼Œä½†è‡ªå®šä¹‰éƒ¨ç½²å¯èƒ½æœ‰ä¸åŒæ ¼å¼
            return (api_key.startswith("sk-") and len(api_key) > 20) or (
                len(api_key) > 30
                and not any(
                    ph in api_key.lower() for ph in ["your", "key", "here", "xxx"]
                )
            )

        elif self.provider == ModelProvider.HUGGINGFACE:
            # HuggingFace APIå¯†é’¥é€šå¸¸ä»¥hf_å¼€å¤´
            return api_key.startswith("hf_") and len(api_key) > 20

        elif self.provider == ModelProvider.HTTP:
            # HTTPæ¨¡å‹æ”¯æŒå¤šç§APIå¯†é’¥æ ¼å¼ï¼Œè¿›è¡Œå®½æ¾éªŒè¯
            return len(api_key) > 10 and not any(
                ph in api_key.lower() for ph in ["your", "key", "here", "xxx"]
            )

        else:
            # å¯¹äºå…¶ä»–æä¾›å•†ï¼Œåªæ£€æŸ¥å¯†é’¥ä¸ä¸ºç©ºä¸”é•¿åº¦åˆç†
            return len(api_key) > 10

    def reload_api_key(self):
        """é‡æ–°åŠ è½½APIå¯†é’¥ï¼ˆç”¨äºè¿è¡Œæ—¶æ›´æ–°ï¼‰"""
        self._load_api_key()

    def get_model_info(self) -> Dict[str, str]:
        """è·å–æ¨¡å‹ä¿¡æ¯æ‘˜è¦"""
        return {
            "name": self.name,
            "provider": self.provider.value,
            "model_id": self.model_id,
            "description": self.description,
            "available": "âœ…" if self.is_available else "âŒ",
            "api_key_status": (
                "å·²é…ç½®" if self.api_key else "æœªé…ç½®" if self.api_key_env else "ä¸éœ€è¦"
            ),
        }


# é¢„å®šä¹‰çš„æ¨¡å‹é…ç½®
MODEL_CONFIGS: Dict[str, ModelConfig] = {
    # OpenAI æ¨¡å‹
    "gpt-4o": ModelConfig(
        name="GPT-4o",
        provider=ModelProvider.OPENAI,
        model_id="gpt-4o",
        api_key_env="OPENAI_API_KEY",
        max_tokens=4096,
        description="OpenAIæœ€æ–°çš„GPT-4oæ¨¡å‹ï¼Œæ€§èƒ½å“è¶Š",
    ),
    "gpt-4-turbo": ModelConfig(
        name="GPT-4 Turbo",
        provider=ModelProvider.OPENAI,
        model_id="gpt-4-turbo-preview",
        api_key_env="OPENAI_API_KEY",
        max_tokens=4096,
        description="OpenAI GPT-4 Turboæ¨¡å‹ï¼Œé€Ÿåº¦æ›´å¿«",
    ),
    "gpt-3.5-turbo": ModelConfig(
        name="GPT-3.5 Turbo",
        provider=ModelProvider.OPENAI,
        model_id="gpt-3.5-turbo",
        api_key_env="OPENAI_API_KEY",
        max_tokens=4096,
        description="OpenAI GPT-3.5 Turboï¼Œç»æµå®ç”¨",
    ),
    # Anthropic æ¨¡å‹
    "claude-3.5-sonnet": ModelConfig(
        name="Claude 3.5 Sonnet",
        provider=ModelProvider.ANTHROPIC,
        model_id="claude-3-5-sonnet-20241022",
        api_key_env="ANTHROPIC_API_KEY",
        max_tokens=4096,
        description="Anthropicæœ€æ–°çš„Claude 3.5 Sonnetæ¨¡å‹",
    ),
    "claude-3-opus": ModelConfig(
        name="Claude 3 Opus",
        provider=ModelProvider.ANTHROPIC,
        model_id="claude-3-opus-20240229",
        api_key_env="ANTHROPIC_API_KEY",
        max_tokens=4096,
        description="Anthropicæœ€å¼ºå¤§çš„Claude 3 Opusæ¨¡å‹",
    ),
    "claude-3-haiku": ModelConfig(
        name="Claude 3 Haiku",
        provider=ModelProvider.ANTHROPIC,
        model_id="claude-3-haiku-20240307",
        api_key_env="ANTHROPIC_API_KEY",
        max_tokens=4096,
        description="Anthropicé€Ÿåº¦æœ€å¿«çš„Claude 3 Haikuæ¨¡å‹",
    ),
    # Groq æ¨¡å‹
    "llama3-70b": ModelConfig(
        name="Llama 3 70B",
        provider=ModelProvider.GROQ,
        model_id="llama3-70b-8192",
        api_key_env="GROQ_API_KEY",
        max_tokens=8192,
        description="Meta Llama 3 70Bï¼Œé«˜æ€§èƒ½å¼€æºæ¨¡å‹",
    ),
    "mixtral-8x7b": ModelConfig(
        name="Mixtral 8x7B",
        provider=ModelProvider.GROQ,
        model_id="mixtral-8x7b-32768",
        api_key_env="GROQ_API_KEY",
        max_tokens=32768,
        description="Mistral AI Mixtral 8x7Bä¸“å®¶æ··åˆæ¨¡å‹",
    ),
    "gemma-7b": ModelConfig(
        name="Gemma 7B",
        provider=ModelProvider.GROQ,
        model_id="gemma-7b-it",
        api_key_env="GROQ_API_KEY",
        max_tokens=8192,
        description="Google Gemma 7BæŒ‡ä»¤è°ƒä¼˜æ¨¡å‹",
    ),
    # DeepSeek æ¨¡å‹
    "deepseek-chat": ModelConfig(
        name="DeepSeek Chat",
        provider=ModelProvider.DEEPSEEK,
        model_id="deepseek-chat",
        api_key_env="DEEPSEEK_API_KEY",
        base_url="https://api.deepseek.com",
        max_tokens=4096,
        description="DeepSeek å¯¹è¯æ¨¡å‹ï¼Œæ€§èƒ½ä¼˜å¼‚",
    ),
    "deepseek-coder": ModelConfig(
        name="DeepSeek Coder",
        provider=ModelProvider.DEEPSEEK,
        model_id="deepseek-coder",
        api_key_env="DEEPSEEK_API_KEY",
        base_url="https://api.deepseek.com",
        max_tokens=4096,
        description="DeepSeek ä»£ç ç”Ÿæˆä¸“ç”¨æ¨¡å‹",
    ),
    "deepseek-r1-huawei": ModelConfig(
        name="DeepSeek-R1 huawei",
        provider=ModelProvider.DEEPSEEK,
        model_id="DeepSeek-R1",
        api_key_env="DEEPSEEK_R1_API_KEY_HUAWEI",
        base_url="https://maas-cn-southwest-2.modelarts-maas.com/v1/infers/8a062fd4-7367-4ab4-a936-5eeb8fb821c4/v1",
        max_tokens=4096,
        temperature=1.0,
        description="è‡ªå®šä¹‰éƒ¨ç½²çš„DeepSeek-R1æ¨¡å‹ï¼Œæ¨ç†èƒ½åŠ›å¼º",
    ),
    # Ollamaæœ¬åœ°æ¨¡å‹ï¼ˆæ— éœ€APIå¯†é’¥ï¼‰
    "llama2": ModelConfig(
        name="Llama 2 Local",
        provider=ModelProvider.OLLAMA,
        model_id="llama2",
        api_key_env="",
        base_url="http://localhost:11434",
        max_tokens=4096,
        description="æœ¬åœ°è¿è¡Œçš„Llama 2æ¨¡å‹",
    ),
    "codellama": ModelConfig(
        name="Code Llama Local",
        provider=ModelProvider.OLLAMA,
        model_id="codellama",
        api_key_env="",
        base_url="http://localhost:11434",
        max_tokens=4096,
        description="æœ¬åœ°è¿è¡Œçš„Code Llamaç¼–ç¨‹ä¸“ç”¨æ¨¡å‹",
    ),
}


class HttpModelDiscovery:
    """HTTPæ¨¡å‹åŠ¨æ€å‘ç°å™¨"""

    # HTTPæ¨¡å‹é…ç½®æ¨¡æ¿
    HTTP_MODEL_TEMPLATES = {
        # åä¸ºäº‘æ¨¡å‹é…ç½®
        "HTTP_DEEPSEEK_R1_API_KEY_HUAWEI": {
            "name": "DeepSeek-R1 (åä¸ºäº‘)",
            "model_id": "DeepSeek-R1",
            "base_url": "https://maas-cn-southwest-2.modelarts-maas.com/v1/infers/8a062fd4-7367-4ab4-a936-5eeb8fb821c4/v1/chat/completions",
            "vendor": "huawei",
            "temperature": 1.0,
            "description": "åä¸ºäº‘éƒ¨ç½²çš„DeepSeek-R1æ¨¡å‹",
        },
        "HTTP_QWEN_API_KEY_HUAWEI": {
            "name": "é€šä¹‰åƒé—® (åä¸ºäº‘)",
            "model_id": "Qwen2.5-72B-Instruct",
            "base_url": "https://maas-cn-southwest-2.modelarts-maas.com/v1/infers/qwen-endpoint/v1/chat/completions",
            "vendor": "huawei",
            "temperature": 0.7,
            "description": "åä¸ºäº‘éƒ¨ç½²çš„é€šä¹‰åƒé—®æ¨¡å‹",
        },
        # é˜¿é‡Œäº‘æ¨¡å‹é…ç½®
        "HTTP_QWEN_API_KEY_ALIBABA": {
            "name": "é€šä¹‰åƒé—® (é˜¿é‡Œäº‘)",
            "model_id": "qwen-plus",
            "base_url": "https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation",
            "vendor": "alibaba",
            "temperature": 0.7,
            "description": "é˜¿é‡Œäº‘é€šä¹‰åƒé—®æ¨¡å‹",
        },
        # ç™¾åº¦äº‘æ¨¡å‹é…ç½®
        "HTTP_ERNIE_API_KEY_BAIDU": {
            "name": "æ–‡å¿ƒä¸€è¨€ (ç™¾åº¦äº‘)",
            "model_id": "ernie-bot-turbo",
            "base_url": "https://aip.baidubce.com/rpc/2.0/ai_custom/v1/wenxinworkshop/chat/eb-instant",
            "vendor": "baidu",
            "temperature": 0.8,
            "description": "ç™¾åº¦äº‘æ–‡å¿ƒä¸€è¨€æ¨¡å‹",
        },
        # é€šç”¨OpenAIå…¼å®¹æ¨¡å‹
        "HTTP_OPENAI_COMPATIBLE_API_KEY": {
            "name": "OpenAIå…¼å®¹æ¨¡å‹",
            "model_id": "gpt-3.5-turbo",
            "base_url": "https://api.openai.com/v1/chat/completions",
            "vendor": "openai-compatible",
            "temperature": 0.7,
            "description": "é€šç”¨OpenAIå…¼å®¹HTTP APIæ¨¡å‹",
        },
    }

    @classmethod
    def discover_http_models(cls) -> Dict[str, ModelConfig]:
        """åŠ¨æ€å‘ç°ç¯å¢ƒä¸­é…ç½®çš„HTTPæ¨¡å‹"""
        discovered_models = {}

        # æ‰«æç¯å¢ƒå˜é‡ï¼Œå¯»æ‰¾HTTP_å¼€å¤´çš„APIå¯†é’¥
        for env_key, api_key in os.environ.items():
            if (
                env_key.startswith("HTTP_")
                and env_key.endswith("_API_KEY")
                or env_key.startswith("HTTP_")
                and "_API_KEY_" in env_key
            ):
                if env_key in cls.HTTP_MODEL_TEMPLATES:
                    template = cls.HTTP_MODEL_TEMPLATES[env_key]

                    # ç”Ÿæˆæ¨¡å‹keyï¼ˆå°å†™ï¼Œç”¨è¿å­—ç¬¦ï¼‰
                    model_key = (
                        env_key.lower().replace("_api_key", "").replace("_", "-")
                    )

                    # åˆ›å»ºModelConfigå®ä¾‹
                    model_config = ModelConfig(
                        name=template["name"],
                        provider=ModelProvider.HTTP,
                        model_id=template["model_id"],
                        api_key_env=env_key,
                        base_url=template["base_url"],
                        max_tokens=4096,
                        temperature=template["temperature"],
                        vendor=template["vendor"],
                        headers={"Content-Type": "application/json"},
                        description=template["description"],
                    )

                    discovered_models[model_key] = model_config

        return discovered_models

    @classmethod
    def get_supported_http_models(cls) -> Dict[str, dict]:
        """è·å–æ”¯æŒçš„HTTPæ¨¡å‹åˆ—è¡¨ï¼ˆä¸è®ºæ˜¯å¦å·²é…ç½®ï¼‰"""
        return cls.HTTP_MODEL_TEMPLATES.copy()


class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨"""

    @staticmethod
    def get_available_models() -> Dict[str, ModelConfig]:
        """è·å–æ‰€æœ‰å¯ç”¨çš„æ¨¡å‹é…ç½®ï¼ˆåŒ…æ‹¬åŠ¨æ€å‘ç°çš„HTTPæ¨¡å‹ï¼‰"""
        models = MODEL_CONFIGS.copy()

        # æ·»åŠ åŠ¨æ€å‘ç°çš„HTTPæ¨¡å‹
        http_models = HttpModelDiscovery.discover_http_models()
        models.update(http_models)

        return models

    @staticmethod
    def get_model_by_provider(provider: ModelProvider) -> Dict[str, ModelConfig]:
        """æ ¹æ®æä¾›å•†ç­›é€‰æ¨¡å‹"""
        return {
            key: config
            for key, config in MODEL_CONFIGS.items()
            if config.provider == provider
        }

    @staticmethod
    def get_model_config(model_key: str) -> Optional[ModelConfig]:
        """è·å–æŒ‡å®šæ¨¡å‹çš„é…ç½®ï¼ˆåŒ…æ‹¬åŠ¨æ€å‘ç°çš„HTTPæ¨¡å‹ï¼‰"""
        # é¦–å…ˆæ£€æŸ¥é¢„å®šä¹‰æ¨¡å‹
        config = MODEL_CONFIGS.get(model_key)
        if config:
            return config

        # æ£€æŸ¥åŠ¨æ€å‘ç°çš„HTTPæ¨¡å‹
        http_models = HttpModelDiscovery.discover_http_models()
        return http_models.get(model_key)

    @staticmethod
    def list_available_models() -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ¨¡å‹çš„é”®å€¼"""
        return list(MODEL_CONFIGS.keys())

    @staticmethod
    def get_models_by_availability() -> Dict[str, ModelConfig]:
        """è·å–å½“å‰ç¯å¢ƒä¸‹å¯ç”¨çš„æ¨¡å‹ï¼ˆæ£€æŸ¥APIå¯†é’¥ï¼‰"""
        available = {}

        # æ£€æŸ¥é¢„å®šä¹‰æ¨¡å‹
        for key, config in MODEL_CONFIGS.items():
            if config.is_available:
                available[key] = config

        # æ£€æŸ¥åŠ¨æ€å‘ç°çš„HTTPæ¨¡å‹
        http_models = HttpModelDiscovery.discover_http_models()
        for key, config in http_models.items():
            if config.is_available:
                available[key] = config

        return available

    @staticmethod
    def add_custom_model(key: str, config: ModelConfig):
        """æ·»åŠ è‡ªå®šä¹‰æ¨¡å‹é…ç½®"""
        MODEL_CONFIGS[key] = config

    @staticmethod
    def reload_all_api_keys():
        """é‡æ–°åŠ è½½æ‰€æœ‰æ¨¡å‹çš„APIå¯†é’¥"""
        for config in MODEL_CONFIGS.values():
            config.reload_api_key()

    @staticmethod
    def get_missing_api_keys() -> Dict[str, List[str]]:
        """è·å–ç¼ºå¤±çš„APIå¯†é’¥ä¿¡æ¯"""
        missing = {}
        for key, config in MODEL_CONFIGS.items():
            if not config.is_available and config.api_key_env:
                provider = config.provider.value
                if provider not in missing:
                    missing[provider] = []
                missing[provider].append(
                    {
                        "model_key": key,
                        "env_var": config.api_key_env,
                        "model_name": config.name,
                    }
                )
        return missing

    @staticmethod
    def validate_environment() -> Dict[str, any]:
        """éªŒè¯ç¯å¢ƒé…ç½®"""
        all_models = ModelManager.get_available_models()
        available_models = ModelManager.get_models_by_availability()
        missing_keys = ModelManager.get_missing_api_keys()

        return {
            "total_models": len(all_models),
            "available_models": len(available_models),
            "missing_keys": missing_keys,
            "availability_rate": (
                len(available_models) / len(all_models) if all_models else 0
            ),
        }

    @staticmethod
    def is_model_available(model_key: str) -> bool:
        """æ£€æŸ¥æŒ‡å®šæ¨¡å‹æ˜¯å¦å¯ç”¨ï¼ˆåŒ…æ‹¬åŠ¨æ€å‘ç°çš„HTTPæ¨¡å‹ï¼‰"""
        # è·å–æ¨¡å‹é…ç½®ï¼ˆåŒ…æ‹¬HTTPæ¨¡å‹ï¼‰
        config = ModelManager.get_model_config(model_key)
        if not config:
            return False

        # æ£€æŸ¥æ¨¡å‹çš„APIå¯†é’¥æ˜¯å¦æ­£ç¡®é…ç½®
        return config.is_available

    @staticmethod
    def get_model_availability_status(model_key: str) -> Dict[str, any]:
        """è·å–æ¨¡å‹å¯ç”¨æ€§çš„è¯¦ç»†çŠ¶æ€ä¿¡æ¯"""
        status = {
            "model_key": model_key,
            "is_available": False,
            "exists_in_config": False,
            "has_api_key": False,
            "api_key_valid_format": False,
            "provider": None,
            "issues": [],
        }

        # æ£€æŸ¥æ¡ä»¶1: æ¨¡å‹æ˜¯å¦åœ¨é¢„å®šä¹‰é…ç½®ä¸­
        config = MODEL_CONFIGS.get(model_key)
        if not config:
            status["issues"].append("æ¨¡å‹æœªåœ¨é¢„å®šä¹‰é…ç½®ä¸­æ‰¾åˆ°")
            return status

        status["exists_in_config"] = True
        status["provider"] = config.provider.value

        # å¯¹äºä¸éœ€è¦APIå¯†é’¥çš„æ¨¡å‹ï¼ˆå¦‚Ollamaï¼‰
        if config.provider == ModelProvider.OLLAMA:
            status["is_available"] = True
            status["has_api_key"] = True  # ä¸éœ€è¦APIå¯†é’¥
            status["api_key_valid_format"] = True
            return status

        # æ£€æŸ¥æ¡ä»¶2: APIå¯†é’¥é…ç½®
        if not config.api_key_env:
            status["issues"].append("æœªå®šä¹‰APIå¯†é’¥ç¯å¢ƒå˜é‡")
            return status

        if not config.api_key or not config.api_key.strip():
            status["issues"].append(
                f"APIå¯†é’¥æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡: {config.api_key_env}"
            )
            return status

        status["has_api_key"] = True

        # æ£€æŸ¥APIå¯†é’¥æ ¼å¼
        if not config._validate_api_key_format():
            status["issues"].append("APIå¯†é’¥æ ¼å¼ä¸æ­£ç¡®æˆ–ä¸ºå ä½ç¬¦")
            return status

        status["api_key_valid_format"] = True
        status["is_available"] = True

        return status


def display_available_models():
    """æ˜¾ç¤ºå½“å‰å¯ç”¨çš„æ¨¡å‹"""
    all_models = ModelManager.get_available_models()
    available_models = ModelManager.get_models_by_availability()

    print("ğŸ¤– æ¨¡å‹é…ç½®çŠ¶æ€ï¼š")
    print("=" * 80)

    # æŒ‰æä¾›å•†åˆ†ç»„æ˜¾ç¤º
    providers = {}
    for key, config in all_models.items():
        provider = config.provider.value
        if provider not in providers:
            providers[provider] = []
        providers[provider].append((key, config))

    for provider, models in providers.items():
        print(f"\nğŸ“¡ {provider.upper()}:")
        for key, config in models:
            info = config.get_model_info()
            status_icon = info["available"]
            print(f"  {status_icon} {key}: {config.name}")
            print(f"    ğŸ“ {config.description}")
            print(f"    ğŸ”‘ APIå¯†é’¥: {info['api_key_status']}")
            if not config.is_available and config.api_key_env:
                print(f"    âš ï¸  è¯·è®¾ç½®ç¯å¢ƒå˜é‡: {config.api_key_env}")

    print("\n" + "=" * 80)
    print(f"ğŸ“Š ç»Ÿè®¡: {len(available_models)}/{len(all_models)} ä¸ªæ¨¡å‹å¯ç”¨")

    if not available_models:
        print("\nâŒ å½“å‰æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·é…ç½®APIå¯†é’¥åé‡è¯•")
        print("ğŸ’¡ æç¤º: ç¼–è¾‘ .env æ–‡ä»¶ï¼Œæ·»åŠ ç›¸åº”çš„APIå¯†é’¥")


def display_detailed_model_info():
    """æ˜¾ç¤ºè¯¦ç»†çš„æ¨¡å‹é…ç½®ä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    print("ğŸ” è¯¦ç»†æ¨¡å‹é…ç½®ä¿¡æ¯ï¼š")
    print("=" * 100)

    for key, config in MODEL_CONFIGS.items():
        info = config.get_model_info()
        print(f"\nğŸ¤– {key}:")
        print(f"  åç§°: {info['name']}")
        print(f"  æä¾›å•†: {info['provider']}")
        print(f"  æ¨¡å‹ID: {config.model_id}")
        print(f"  ç¯å¢ƒå˜é‡: {config.api_key_env}")
        print(f"  APIå¯†é’¥çŠ¶æ€: {info['api_key_status']}")
        print(f"  å¯ç”¨çŠ¶æ€: {info['available']}")
        if config.base_url:
            print(f"  åŸºç¡€URL: {config.base_url}")
        print(f"  æè¿°: {info['description']}")

    print("\n" + "=" * 100)


def display_environment_setup_guide():
    """æ˜¾ç¤ºç¯å¢ƒè®¾ç½®æŒ‡å—"""
    validation = ModelManager.validate_environment()
    missing_keys = validation["missing_keys"]

    print("ğŸ”§ ç¯å¢ƒé…ç½®æŒ‡å—")
    print("=" * 60)

    print(
        f"ğŸ“Š æ¨¡å‹å¯ç”¨æ€§: {validation['available_models']}/{validation['total_models']} "
        f"({validation['availability_rate']:.1%})"
    )

    if not missing_keys:
        print("âœ… æ‰€æœ‰éœ€è¦çš„APIå¯†é’¥éƒ½å·²é…ç½®ï¼")
        return

    print("\nâŒ ç¼ºå¤±çš„APIå¯†é’¥é…ç½®ï¼š")

    for provider, models in missing_keys.items():
        print(f"\nğŸ“¡ {provider.upper()}:")
        env_vars = set(model["env_var"] for model in models)
        for env_var in env_vars:
            print(f"  ğŸ”‘ {env_var}")
            affected_models = [
                m["model_name"] for m in models if m["env_var"] == env_var
            ]
            print(f"    å½±å“æ¨¡å‹: {', '.join(affected_models)}")

    print("\nğŸ’¡ é…ç½®æ­¥éª¤ï¼š")
    print("1. ç¼–è¾‘é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶")
    print("2. æ·»åŠ æˆ–æ›´æ–°ç›¸åº”çš„APIå¯†é’¥ï¼š")

    for provider, models in missing_keys.items():
        env_vars = set(model["env_var"] for model in models)
        for env_var in env_vars:
            print(f"   {env_var}=your-api-key-here")

    print("3. é‡æ–°è¿è¡Œç¨‹åº")
    print("\nğŸ“ è·å–APIå¯†é’¥çš„åœ°å€ï¼š")
    print("   - OpenAI: https://platform.openai.com/api-keys")
    print("   - Anthropic: https://console.anthropic.com/")
    print("   - Groq: https://console.groq.com/keys")
    print("   - DeepSeek: https://platform.deepseek.com/")
    print("   - HuggingFace: https://huggingface.co/settings/tokens")

    print("\n" + "=" * 60)


def quick_setup_check():
    """å¿«é€Ÿè®¾ç½®æ£€æŸ¥"""
    validation = ModelManager.validate_environment()

    if validation["availability_rate"] >= 1.0:
        print("âœ… ç¯å¢ƒé…ç½®å®Œå–„ï¼æ‰€æœ‰æ¨¡å‹éƒ½å¯ç”¨")
        return True
    elif validation["available_models"] > 0:
        print(
            f"âš ï¸  éƒ¨åˆ†æ¨¡å‹å¯ç”¨ ({validation['available_models']}/{validation['total_models']})"
        )
        return True
    else:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œè¯·é…ç½®APIå¯†é’¥")
        display_environment_setup_guide()
        return False


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹ç®¡ç†å™¨
    display_available_models()
