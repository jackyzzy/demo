# AI Agentå®ä¾‹ä»£ç ï¼šLangGraphä¸Agnoæ¡†æ¶å®Œæ•´å®ç°

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›ä¸¤ä¸ªåŠŸèƒ½å®Œæ•´çš„AI agentå®ä¾‹ä»£ç ï¼Œåˆ†åˆ«åŸºäº**LangGraphæ¡†æ¶**å’Œ**Agnoæ¡†æ¶**å¼€å‘ã€‚ä¸¤ä¸ªagentéƒ½å…·å¤‡å¯¹è¯ã€å¤šæ­¥æ¨ç†ã€å·¥å…·è°ƒç”¨å’Œä»»åŠ¡è§„åˆ’èƒ½åŠ›ã€‚

## 1. LangGraph Agentå®ç°

### 1.1 ç¯å¢ƒæ­å»º

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv langgraph_env
source langgraph_env/bin/activate  # Windows: langgraph_env\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -U langgraph langchain-openai langchain-community
pip install tavily-python duckduckgo-search yfinance
pip install python-dotenv pydantic typing-extensions

# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="sk-your-key-here"
export TAVILY_API_KEY="tvly-your-key-here"
```

### 1.2 å®Œæ•´ä»£ç å®ç°

```python
"""
LangGraphæ™ºèƒ½åŠ©æ‰‹ - å®Œæ•´å®ç°
åŠŸèƒ½ï¼šå¯¹è¯ã€å¤šæ­¥æ¨ç†ã€å·¥å…·è°ƒç”¨ã€ä»»åŠ¡è§„åˆ’
ä½œè€…ï¼šAI Assistant
ç‰ˆæœ¬ï¼š1.0
"""

import os
from typing import List, Dict, Any, Literal, Annotated
from typing_extensions import TypedDict
from dataclasses import dataclass
import json
from datetime import datetime

# LangGraphç›¸å…³å¯¼å…¥
from langgraph.graph import StateGraph, START, END
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command

# LangChainç›¸å…³å¯¼å…¥
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.tools import tool

# å·¥å…·å¯¼å…¥
from tavily import TavilyClient
from duckduckgo_search import DDGS
import yfinance as yf

# ç¯å¢ƒé…ç½®
from dotenv import load_dotenv
load_dotenv()

# ========== çŠ¶æ€å®šä¹‰ ==========
class AgentState(TypedDict):
    """æ™ºèƒ½ä½“çŠ¶æ€å®šä¹‰"""
    messages: List[Any]  # æ¶ˆæ¯å†å²
    current_task: str   # å½“å‰ä»»åŠ¡
    task_type: str      # ä»»åŠ¡ç±»å‹ï¼šsimple_chat, research, analysis, planning
    search_results: List[Dict]  # æœç´¢ç»“æœ
    analysis_results: Dict[str, Any]  # åˆ†æç»“æœ
    reasoning_steps: List[str]  # æ¨ç†æ­¥éª¤
    plan: List[Dict]    # ä»»åŠ¡è®¡åˆ’
    completed_steps: List[str]  # å·²å®Œæˆæ­¥éª¤
    context: Dict[str, Any]  # ä¸Šä¸‹æ–‡ä¿¡æ¯
    next_action: str    # ä¸‹ä¸€æ­¥åŠ¨ä½œ


# ========== å·¥å…·å®šä¹‰ ==========
@tool
def web_search(query: str, max_results: int = 5) -> str:
    """
    ä½¿ç”¨Tavilyæœç´¢å¼•æ“è¿›è¡Œç½‘ç»œæœç´¢
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        max_results: æœ€å¤§ç»“æœæ•°
    
    Returns:
        str: æœç´¢ç»“æœæ‘˜è¦
    """
    try:
        client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
        response = client.search(
            query=query,
            search_depth="advanced",
            max_results=max_results,
            include_answer=True
        )
        
        results = []
        for result in response.get("results", []):
            results.append(f"æ ‡é¢˜: {result['title']}\nå†…å®¹: {result['content'][:300]}...\nURL: {result['url']}")
        
        return "\n\n---\n\n".join(results)
    except Exception as e:
        return f"æœç´¢å¤±è´¥: {str(e)}"


@tool
def duckduckgo_search(query: str, max_results: int = 5) -> str:
    """
    ä½¿ç”¨DuckDuckGoè¿›è¡Œéšç§å‹å¥½çš„æœç´¢
    
    Args:
        query: æœç´¢æŸ¥è¯¢
        max_results: æœ€å¤§ç»“æœæ•°
    
    Returns:
        str: æœç´¢ç»“æœ
    """
    try:
        ddgs = DDGS()
        results = list(ddgs.text(query, max_results=max_results))
        
        formatted_results = []
        for result in results:
            formatted_results.append(f"æ ‡é¢˜: {result['title']}\næ‘˜è¦: {result['body']}\nURL: {result['href']}")
        
        return "\n\n---\n\n".join(formatted_results)
    except Exception as e:
        return f"DuckDuckGoæœç´¢å¤±è´¥: {str(e)}"


@tool
def get_stock_info(symbol: str) -> str:
    """
    è·å–è‚¡ç¥¨ä¿¡æ¯
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç  (å¦‚: AAPL, TSLA)
    
    Returns:
        str: è‚¡ç¥¨ä¿¡æ¯
    """
    try:
        stock = yf.Ticker(symbol)
        info = stock.info
        hist = stock.history(period="1d")
        
        result = f"""
è‚¡ç¥¨ä»£ç : {symbol}
å…¬å¸åç§°: {info.get('longName', 'N/A')}
å½“å‰ä»·æ ¼: ${info.get('currentPrice', 'N/A')}
å¸‚å€¼: ${info.get('marketCap', 'N/A'):,} 
52å‘¨æœ€é«˜: ${info.get('fiftyTwoWeekHigh', 'N/A')}
52å‘¨æœ€ä½: ${info.get('fiftyTwoWeekLow', 'N/A')}
è¡Œä¸š: {info.get('industry', 'N/A')}
ç®€ä»‹: {info.get('longBusinessSummary', 'N/A')[:200]}...
        """
        return result
    except Exception as e:
        return f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}"


@tool
def calculator(expression: str) -> str:
    """
    æ‰§è¡Œæ•°å­¦è®¡ç®—
    
    Args:
        expression: æ•°å­¦è¡¨è¾¾å¼
    
    Returns:
        str: è®¡ç®—ç»“æœ
    """
    try:
        # å®‰å…¨çš„æ•°å­¦è¡¨è¾¾å¼è®¡ç®—
        allowed_chars = set('0123456789+-*/(). ')
        if not all(c in allowed_chars for c in expression):
            return "è®¡ç®—è¡¨è¾¾å¼åŒ…å«ä¸å…è®¸çš„å­—ç¬¦"
        
        result = eval(expression)
        return f"è®¡ç®—ç»“æœ: {expression} = {result}"
    except Exception as e:
        return f"è®¡ç®—é”™è¯¯: {str(e)}"


# å·¥å…·åˆ—è¡¨
tools = [web_search, duckduckgo_search, get_stock_info, calculator]


# ========== æ ¸å¿ƒAgentç±» ==========
class LangGraphAgent:
    """åŸºäºLangGraphçš„æ™ºèƒ½åŠ©æ‰‹"""
    
    def __init__(self, model_name: str = "gpt-4o"):
        """
        åˆå§‹åŒ–æ™ºèƒ½åŠ©æ‰‹
        
        Args:
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.llm = ChatOpenAI(model=model_name, temperature=0.1)
        self.memory = MemorySaver()
        
        # åˆ›å»ºå·¥å…·èŠ‚ç‚¹
        self.tool_node = ToolNode(tools)
        
        # æ„å»ºå›¾
        self.app = self._build_graph()
        
        print(f"âœ… LangGraphæ™ºèƒ½åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {model_name}")
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraphå·¥ä½œæµå›¾"""
        
        # åˆ›å»ºçŠ¶æ€å›¾
        workflow = StateGraph(AgentState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("classifier", self._classify_task)          # ä»»åŠ¡åˆ†ç±»
        workflow.add_node("simple_chat", self._simple_chat)           # ç®€å•å¯¹è¯
        workflow.add_node("planner", self._create_plan)              # ä»»åŠ¡è§„åˆ’
        workflow.add_node("researcher", self._research_node)          # ç ”ç©¶èŠ‚ç‚¹
        workflow.add_node("analyzer", self._analysis_node)           # åˆ†æèŠ‚ç‚¹
        workflow.add_node("reasoning", self._reasoning_node)         # æ¨ç†èŠ‚ç‚¹
        workflow.add_node("tools", self.tool_node)                   # å·¥å…·è°ƒç”¨
        workflow.add_node("synthesizer", self._synthesize_results)   # ç»“æœç»¼åˆ
        
        # æ·»åŠ è¾¹å’Œæ¡ä»¶è·¯ç”±
        workflow.add_edge(START, "classifier")
        
        # ä»åˆ†ç±»å™¨åˆ°ä¸åŒå¤„ç†è·¯å¾„
        workflow.add_conditional_edges(
            "classifier",
            self._route_after_classification,
            {
                "simple_chat": "simple_chat",
                "research": "planner", 
                "analysis": "planner",
                "planning": "planner"
            }
        )
        
        # ç®€å•å¯¹è¯è·¯å¾„
        workflow.add_conditional_edges(
            "simple_chat",
            tools_condition,
            {
                "tools": "tools",
                "end": END
            }
        )
        
        # å·¥å…·è°ƒç”¨åå›åˆ°ç®€å•å¯¹è¯
        workflow.add_edge("tools", "simple_chat")
        
        # è§„åˆ’åçš„è·¯å¾„
        workflow.add_edge("planner", "researcher")
        workflow.add_edge("researcher", "analyzer")  
        workflow.add_edge("analyzer", "reasoning")
        workflow.add_edge("reasoning", "synthesizer")
        workflow.add_edge("synthesizer", END)
        
        return workflow.compile(checkpointer=self.memory)
    
    def _classify_task(self, state: AgentState) -> Dict[str, Any]:
        """ä»»åŠ¡åˆ†ç±»èŠ‚ç‚¹"""
        messages = state.get("messages", [])
        if not messages:
            return {"task_type": "simple_chat"}
            
        last_message = messages[-1].content if messages else ""
        
        # ä½¿ç”¨LLMè¿›è¡Œä»»åŠ¡åˆ†ç±»
        classification_prompt = f"""
        åˆ†æç”¨æˆ·çš„è¯·æ±‚ï¼Œå°†å…¶åˆ†ç±»ä¸ºä»¥ä¸‹ç±»å‹ä¹‹ä¸€ï¼š
        1. simple_chat - ç®€å•å¯¹è¯ã€é—®å€™ã€åŸºæœ¬é—®ç­”
        2. research - éœ€è¦æœç´¢ä¿¡æ¯çš„ç ”ç©¶ä»»åŠ¡
        3. analysis - éœ€è¦æ·±åº¦åˆ†æçš„ä»»åŠ¡
        4. planning - éœ€è¦åˆ¶å®šè®¡åˆ’æˆ–ç­–ç•¥çš„ä»»åŠ¡
        
        ç”¨æˆ·è¯·æ±‚: {last_message}
        
        åªè¿”å›ç±»å‹åç§°ï¼Œä¸è¦å…¶ä»–æ–‡å­—ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=classification_prompt)])
        task_type = response.content.strip().lower()
        
        # éªŒè¯è¿”å›å€¼
        valid_types = ["simple_chat", "research", "analysis", "planning"]
        if task_type not in valid_types:
            task_type = "simple_chat"
        
        return {
            "task_type": task_type,
            "current_task": last_message,
            "reasoning_steps": [f"ä»»åŠ¡åˆ†ç±»: {task_type}"]
        }
    
    def _simple_chat(self, state: AgentState) -> Dict[str, Any]:
        """ç®€å•å¯¹è¯å¤„ç†èŠ‚ç‚¹"""
        messages = state.get("messages", [])
        
        # æ„å»ºå¯¹è¯æç¤º
        system_prompt = """
        ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€æœ‰ç”¨çš„AIåŠ©æ‰‹ã€‚ä½ å¯ä»¥ï¼š
        1. è¿›è¡Œæ—¥å¸¸å¯¹è¯
        2. å›ç­”ä¸€èˆ¬æ€§é—®é¢˜
        3. åœ¨éœ€è¦æ—¶è°ƒç”¨å·¥å…·è·å–ä¿¡æ¯
        4. è¿›è¡Œæ•°å­¦è®¡ç®—
        5. æœç´¢æœ€æ–°ä¿¡æ¯
        
        å¦‚æœç”¨æˆ·çš„é—®é¢˜éœ€è¦æœç´¢æœ€æ–°ä¿¡æ¯ã€è‚¡ç¥¨æ•°æ®æˆ–æ•°å­¦è®¡ç®—ï¼Œè¯·è°ƒç”¨ç›¸åº”çš„å·¥å…·ã€‚
        """
        
        full_messages = [{"role": "system", "content": system_prompt}] + [
            {"role": "human" if isinstance(msg, HumanMessage) else "ai", 
             "content": msg.content} for msg in messages
        ]
        
        response = self.llm.bind_tools(tools).invoke(full_messages)
        
        return {
            "messages": messages + [response]
        }
    
    def _create_plan(self, state: AgentState) -> Dict[str, Any]:
        """ä»»åŠ¡è§„åˆ’èŠ‚ç‚¹"""
        current_task = state.get("current_task", "")
        task_type = state.get("task_type", "")
        
        planning_prompt = f"""
        ä¸ºä»¥ä¸‹{task_type}ä»»åŠ¡åˆ¶å®šè¯¦ç»†çš„æ‰§è¡Œè®¡åˆ’ï¼š
        
        ä»»åŠ¡: {current_task}
        
        è¯·å°†ä»»åŠ¡åˆ†è§£ä¸ºå…·ä½“çš„æ­¥éª¤ï¼Œæ¯ä¸ªæ­¥éª¤åŒ…æ‹¬ï¼š
        1. æ­¥éª¤åç§°
        2. å…·ä½“è¡ŒåŠ¨
        3. é¢„æœŸç»“æœ
        
        ä»¥JSONæ ¼å¼è¿”å›è®¡åˆ’ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
        {{
            "steps": [
                {{
                    "name": "æ­¥éª¤åç§°",
                    "action": "å…·ä½“è¡ŒåŠ¨", 
                    "expected_result": "é¢„æœŸç»“æœ"
                }}
            ]
        }}
        """
        
        response = self.llm.invoke([HumanMessage(content=planning_prompt)])
        
        try:
            plan_data = json.loads(response.content)
            plan = plan_data.get("steps", [])
        except:
            # å¦‚æœJSONè§£æå¤±è´¥ï¼Œåˆ›å»ºé»˜è®¤è®¡åˆ’
            plan = [
                {
                    "name": "ä¿¡æ¯æ”¶é›†",
                    "action": "æœç´¢ç›¸å…³ä¿¡æ¯",
                    "expected_result": "è·å¾—èƒŒæ™¯ä¿¡æ¯"
                },
                {
                    "name": "æ·±åº¦åˆ†æ", 
                    "action": "åˆ†ææ”¶é›†åˆ°çš„ä¿¡æ¯",
                    "expected_result": "å½¢æˆåˆæ­¥ç»“è®º"
                },
                {
                    "name": "æ¨ç†ç»¼åˆ",
                    "action": "è¿›è¡Œé€»è¾‘æ¨ç†",
                    "expected_result": "å¾—å‡ºæœ€ç»ˆç­”æ¡ˆ"
                }
            ]
        
        reasoning_steps = state.get("reasoning_steps", [])
        reasoning_steps.append(f"åˆ¶å®šäº†åŒ…å«{len(plan)}ä¸ªæ­¥éª¤çš„æ‰§è¡Œè®¡åˆ’")
        
        return {
            "plan": plan,
            "reasoning_steps": reasoning_steps
        }
    
    def _research_node(self, state: AgentState) -> Dict[str, Any]:
        """ç ”ç©¶ä¿¡æ¯æ”¶é›†èŠ‚ç‚¹"""
        current_task = state.get("current_task", "")
        plan = state.get("plan", [])
        
        # æ‰§è¡Œç ”ç©¶æ­¥éª¤
        search_queries = self._generate_search_queries(current_task)
        search_results = []
        
        for query in search_queries[:3]:  # é™åˆ¶æœç´¢æŸ¥è¯¢æ•°é‡
            try:
                # ä½¿ç”¨Tavilyæœç´¢
                result = web_search.invoke({"query": query, "max_results": 3})
                search_results.append({
                    "query": query,
                    "results": result
                })
            except:
                # å¤‡ç”¨DuckDuckGoæœç´¢
                try:
                    result = duckduckgo_search.invoke({"query": query, "max_results": 3})
                    search_results.append({
                        "query": query, 
                        "results": result
                    })
                except:
                    pass
        
        reasoning_steps = state.get("reasoning_steps", [])
        reasoning_steps.append(f"å®Œæˆä¿¡æ¯æ”¶é›†ï¼Œè·å¾—{len(search_results)}ç»„æœç´¢ç»“æœ")
        
        return {
            "search_results": search_results,
            "reasoning_steps": reasoning_steps
        }
    
    def _analysis_node(self, state: AgentState) -> Dict[str, Any]:
        """åˆ†æå¤„ç†èŠ‚ç‚¹"""
        search_results = state.get("search_results", [])
        current_task = state.get("current_task", "")
        
        # æ•´åˆæœç´¢ç»“æœ
        all_info = ""
        for result in search_results:
            all_info += f"æŸ¥è¯¢: {result['query']}\nç»“æœ: {result['results']}\n\n"
        
        analysis_prompt = f"""
        åŸºäºæ”¶é›†åˆ°çš„ä¿¡æ¯ï¼Œå¯¹ä»¥ä¸‹ä»»åŠ¡è¿›è¡Œæ·±åº¦åˆ†æï¼š
        
        ä»»åŠ¡: {current_task}
        
        æ”¶é›†åˆ°çš„ä¿¡æ¯:
        {all_info}
        
        è¯·è¿›è¡Œå¤šè§’åº¦åˆ†æï¼š
        1. å…³é”®ä¿¡æ¯æ€»ç»“
        2. é‡è¦å‘ç°å’Œè¶‹åŠ¿
        3. ä¸åŒè§‚ç‚¹å¯¹æ¯”
        4. æ½œåœ¨å½±å“å’Œæ„ä¹‰
        
        è¯·ä»¥ç»“æ„åŒ–æ–¹å¼ç»„ç»‡åˆ†æç»“æœã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=analysis_prompt)])
        
        analysis_results = {
            "summary": "åˆ†æå®Œæˆ",
            "content": response.content,
            "timestamp": datetime.now().isoformat()
        }
        
        reasoning_steps = state.get("reasoning_steps", [])
        reasoning_steps.append("å®Œæˆä¿¡æ¯åˆ†æï¼Œå½¢æˆç»“æ„åŒ–è§è§£")
        
        return {
            "analysis_results": analysis_results,
            "reasoning_steps": reasoning_steps
        }
    
    def _reasoning_node(self, state: AgentState) -> Dict[str, Any]:
        """æ¨ç†æ€è€ƒèŠ‚ç‚¹"""
        analysis_results = state.get("analysis_results", {})
        current_task = state.get("current_task", "")
        
        reasoning_prompt = f"""
        åŸºäºåˆ†æç»“æœï¼Œè¯·è¿›è¡Œé€æ­¥æ¨ç†æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š
        
        åŸå§‹é—®é¢˜: {current_task}
        åˆ†æç»“æœ: {analysis_results.get('content', '')}
        
        è¯·ä½¿ç”¨ä»¥ä¸‹æ¨ç†æ¡†æ¶ï¼š
        
        1. é—®é¢˜ç†è§£ï¼šé‡æ–°é˜è¿°æ ¸å¿ƒé—®é¢˜
        2. å…³é”®å› ç´ ï¼šè¯†åˆ«å½±å“ç­”æ¡ˆçš„å…³é”®å› ç´   
        3. é€»è¾‘æ¨ç†ï¼š
           - æ­¥éª¤1ï¼š[åŸºäºè¯æ®Aå¾—å‡ºç»“è®º1]
           - æ­¥éª¤2ï¼š[åŸºäºè¯æ®Bå¾—å‡ºç»“è®º2]
           - æ­¥éª¤3ï¼š[ç»¼åˆç»“è®º1å’Œ2å¾—å‡ºæœ€ç»ˆç»“è®º]
        4. éªŒè¯æ£€æŸ¥ï¼šæ£€éªŒç»“è®ºçš„åˆç†æ€§
        5. æœ€ç»ˆç­”æ¡ˆï¼šæ¸…æ™°æ˜ç¡®çš„å›ç­”
        
        è¯·ä¸¥æ ¼æŒ‰ç…§è¿™ä¸ªç»“æ„è¿›è¡Œæ¨ç†ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=reasoning_prompt)])
        
        reasoning_steps = state.get("reasoning_steps", [])
        reasoning_steps.append("å®Œæˆé€»è¾‘æ¨ç†åˆ†æ")
        
        return {
            "reasoning_steps": reasoning_steps,
            "reasoning_content": response.content
        }
    
    def _synthesize_results(self, state: AgentState) -> Dict[str, Any]:
        """ç»“æœç»¼åˆèŠ‚ç‚¹"""
        current_task = state.get("current_task", "")
        analysis_results = state.get("analysis_results", {})
        reasoning_content = state.get("reasoning_content", "")
        reasoning_steps = state.get("reasoning_steps", [])
        
        synthesis_prompt = f"""
        è¯·å°†æ‰€æœ‰åˆ†æå’Œæ¨ç†ç»“æœç»¼åˆæˆä¸€ä¸ªå®Œæ•´ã€æ¸…æ™°çš„æœ€ç»ˆå›ç­”ï¼š
        
        åŸå§‹é—®é¢˜: {current_task}
        
        åˆ†æç»“æœ: {analysis_results.get('content', '')}
        
        æ¨ç†è¿‡ç¨‹: {reasoning_content}
        
        è¯·æä¾›ï¼š
        1. ç›´æ¥æ˜ç¡®çš„ç­”æ¡ˆ
        2. æ”¯æŒè¯æ®å’Œç†ç”±
        3. ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯
        4. å¦‚æœæœ‰çš„è¯ï¼Œå»ºè®®ä¸‹ä¸€æ­¥è¡ŒåŠ¨
        
        è¯·ä»¥è‡ªç„¶ã€æ˜“æ‡‚çš„æ–¹å¼ç»„ç»‡å›ç­”ã€‚
        """
        
        final_response = self.llm.invoke([HumanMessage(content=synthesis_prompt)])
        
        reasoning_steps.append("å®Œæˆç»“æœç»¼åˆï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”")
        
        messages = state.get("messages", [])
        messages.append(AIMessage(content=final_response.content))
        
        return {
            "messages": messages,
            "reasoning_steps": reasoning_steps
        }
    
    def _generate_search_queries(self, task: str) -> List[str]:
        """ç”Ÿæˆæœç´¢æŸ¥è¯¢"""
        query_prompt = f"""
        ä¸ºä»¥ä¸‹ä»»åŠ¡ç”Ÿæˆ2-3ä¸ªæœ‰æ•ˆçš„æœç´¢æŸ¥è¯¢ï¼š
        
        ä»»åŠ¡: {task}
        
        è¯·ç”Ÿæˆèƒ½å¤Ÿè·å¾—ç›¸å…³ã€å‡†ç¡®ä¿¡æ¯çš„æœç´¢æŸ¥è¯¢ã€‚
        æ¯è¡Œä¸€ä¸ªæŸ¥è¯¢ï¼Œä¸è¦ç¼–å·ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=query_prompt)])
        queries = [q.strip() for q in response.content.split('\n') if q.strip()]
        
        return queries[:3]  # é™åˆ¶æŸ¥è¯¢æ•°é‡
    
    def _route_after_classification(self, state: AgentState) -> str:
        """åˆ†ç±»åçš„è·¯ç”±å†³ç­–"""
        task_type = state.get("task_type", "simple_chat")
        return task_type
    
    def chat(self, message: str, session_id: str = "default") -> str:
        """
        ä¸æ™ºèƒ½åŠ©æ‰‹å¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯IDï¼Œç”¨äºç»´æŠ¤å¯¹è¯å†å²
        
        Returns:
            str: åŠ©æ‰‹å›å¤
        """
        try:
            # å‡†å¤‡åˆå§‹çŠ¶æ€
            initial_state = {
                "messages": [HumanMessage(content=message)],
                "current_task": "",
                "task_type": "",
                "search_results": [],
                "analysis_results": {},
                "reasoning_steps": [],
                "plan": [],
                "completed_steps": [],
                "context": {},
                "next_action": ""
            }
            
            # æ‰§è¡Œå›¾å¤„ç†
            config = {"configurable": {"thread_id": session_id}}
            final_state = self.app.invoke(initial_state, config=config)
            
            # æå–å›å¤
            messages = final_state.get("messages", [])
            if messages and isinstance(messages[-1], AIMessage):
                return messages[-1].content
            else:
                return "æŠ±æ­‰ï¼Œå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°äº†é—®é¢˜ã€‚"
                
        except Exception as e:
            return f"å¯¹è¯å¤„ç†å¤±è´¥: {str(e)}"
    
    def get_reasoning_steps(self, session_id: str = "default") -> List[str]:
        """è·å–æ¨ç†æ­¥éª¤"""
        try:
            config = {"configurable": {"thread_id": session_id}}
            state = self.app.get_state(config)
            return state.values.get("reasoning_steps", [])
        except:
            return []


# ========== ä½¿ç”¨ç¤ºä¾‹ ==========
def demo_langgraph_agent():
    """LangGraph Agent æ¼”ç¤º"""
    print("\n" + "="*60)
    print("ğŸš€ LangGraphæ™ºèƒ½åŠ©æ‰‹æ¼”ç¤º")
    print("="*60)
    
    # åˆ›å»ºæ™ºèƒ½åŠ©æ‰‹
    agent = LangGraphAgent()
    
    # æµ‹è¯•åœºæ™¯
    test_cases = [
        {
            "name": "ç®€å•å¯¹è¯",
            "message": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±çš„èƒ½åŠ›"
        },
        {
            "name": "æ•°å­¦è®¡ç®—", 
            "message": "è¯·å¸®æˆ‘è®¡ç®— (125 + 75) * 2 - 50"
        },
        {
            "name": "ä¿¡æ¯ç ”ç©¶",
            "message": "è¯·è°ƒç ”ä¸€ä¸‹2024å¹´äººå·¥æ™ºèƒ½çš„æœ€æ–°å‘å±•è¶‹åŠ¿"
        },
        {
            "name": "è‚¡ç¥¨åˆ†æ",
            "message": "åˆ†æä¸€ä¸‹ç‰¹æ–¯æ‹‰(TSLA)è‚¡ç¥¨çš„æŠ•èµ„ä»·å€¼"
        }
    ]
    
    for i, test in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ æµ‹è¯•{i}ï¼š{test['name']}")
        print(f"é—®é¢˜ï¼š{test['message']}")
        print("\nğŸ’­ å¤„ç†ä¸­...")
        
        response = agent.chat(test['message'], session_id=f"demo_{i}")
        
        print(f"\nğŸ¤– å›ç­”ï¼š")
        print(response)
        
        # æ˜¾ç¤ºæ¨ç†æ­¥éª¤
        steps = agent.get_reasoning_steps(f"demo_{i}")
        if steps:
            print(f"\nğŸ§  æ¨ç†æ­¥éª¤ï¼š")
            for step in steps:
                print(f"  â€¢ {step}")
        
        print("\n" + "-"*40)
    
    print("\nâœ… LangGraph Agentæ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    demo_langgraph_agent()
```

---

## 2. Agno Agentå®ç°

### 2.1 ç¯å¢ƒæ­å»º

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv agno_env
source agno_env/bin/activate  # Windows: agno_env\Scripts\activate

# å®‰è£…ä¾èµ–
pip install -U agno openai anthropic
pip install tavily-python duckduckgo-search yfinance
pip install python-dotenv

# è®¾ç½®ç¯å¢ƒå˜é‡
export OPENAI_API_KEY="sk-your-key-here"
export ANTHROPIC_API_KEY="sk-ant-your-key-here"
export TAVILY_API_KEY="tvly-your-key-here"
```

### 2.2 å®Œæ•´ä»£ç å®ç°

```python
"""
Agnoæ™ºèƒ½åŠ©æ‰‹ - å®Œæ•´å®ç°
åŠŸèƒ½ï¼šå¯¹è¯ã€å¤šæ­¥æ¨ç†ã€å·¥å…·è°ƒç”¨ã€ä»»åŠ¡è§„åˆ’
ä½œè€…ï¼šAI Assistant
ç‰ˆæœ¬ï¼š1.0
"""

import os
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import json
from datetime import datetime

# Agnoæ¡†æ¶å¯¼å…¥
from agno.agent import Agent
from agno.team import Team  
from agno.workflow import Workflow
from agno.models.openai import OpenAIChat
from agno.models.anthropic import Claude
from agno.tools import Tool
from agno.tools.duckduckgo import DuckDuckGoTools
from agno.tools.yfinance import YFinanceTools
from agno.tools.reasoning import ReasoningTools

# å…¶ä»–å¯¼å…¥
from tavily import TavilyClient
import yfinance as yf

# ç¯å¢ƒé…ç½®
from dotenv import load_dotenv
load_dotenv()


# ========== è‡ªå®šä¹‰å·¥å…·ç±» ==========
class TavilySearchTool(Tool):
    """Tavilyæœç´¢å·¥å…·"""
    
    def __init__(self):
        super().__init__(
            name="tavily_search",
            description="ä½¿ç”¨Tavilyæœç´¢å¼•æ“è¿›è¡Œé«˜è´¨é‡ç½‘ç»œæœç´¢ï¼Œä¸“ä¸ºAIä¼˜åŒ–",
        )
        self.client = TavilyClient(api_key=os.getenv("TAVILY_API_KEY"))
    
    def run(self, query: str, max_results: int = 5) -> str:
        """æ‰§è¡Œæœç´¢"""
        try:
            response = self.client.search(
                query=query,
                search_depth="advanced", 
                max_results=max_results,
                include_answer=True
            )
            
            results = []
            for result in response.get("results", []):
                results.append(
                    f"æ ‡é¢˜: {result['title']}\n"
                    f"å†…å®¹: {result['content'][:300]}...\n"
                    f"URL: {result['url']}\n"
                )
            
            return "\n---\n".join(results)
        except Exception as e:
            return f"Tavilyæœç´¢å¤±è´¥: {str(e)}"


class AdvancedCalculatorTool(Tool):
    """é«˜çº§è®¡ç®—å™¨å·¥å…·"""
    
    def __init__(self):
        super().__init__(
            name="advanced_calculator",
            description="æ‰§è¡Œæ•°å­¦è®¡ç®—ã€ç»Ÿè®¡åˆ†æç­‰è¿ç®—",
        )
    
    def run(self, expression: str) -> str:
        """æ‰§è¡Œè®¡ç®—"""
        try:
            # å®‰å…¨è®¡ç®—
            allowed_chars = set('0123456789+-*/().eE ')
            allowed_words = {'sin', 'cos', 'tan', 'log', 'exp', 'sqrt', 'pi', 'abs'}
            
            # åŸºæœ¬å®‰å…¨æ£€æŸ¥
            clean_expr = expression.replace(' ', '')
            if not all(c in allowed_chars or c.isalpha() for c in clean_expr):
                return "è¡¨è¾¾å¼åŒ…å«ä¸å…è®¸çš„å­—ç¬¦"
            
            # ç®€å•æ•°å­¦è¿ç®—
            import math
            safe_dict = {
                "__builtins__": {},
                "sin": math.sin, "cos": math.cos, "tan": math.tan,
                "log": math.log, "exp": math.exp, "sqrt": math.sqrt,
                "pi": math.pi, "abs": abs, "pow": pow
            }
            
            result = eval(expression, safe_dict)
            return f"è®¡ç®—ç»“æœ: {expression} = {result}"
        except Exception as e:
            return f"è®¡ç®—é”™è¯¯: {str(e)}"


class EnhancedStockTool(Tool):
    """å¢å¼ºè‚¡ç¥¨åˆ†æå·¥å…·"""
    
    def __init__(self):
        super().__init__(
            name="enhanced_stock_analysis",
            description="è·å–è¯¦ç»†çš„è‚¡ç¥¨ä¿¡æ¯ã€è´¢åŠ¡æ•°æ®å’ŒæŠ€æœ¯åˆ†æ",
        )
    
    def run(self, symbol: str) -> str:
        """è·å–è‚¡ç¥¨è¯¦ç»†ä¿¡æ¯"""
        try:
            stock = yf.Ticker(symbol)
            info = stock.info
            hist = stock.history(period="1mo")
            
            # åŸºæœ¬ä¿¡æ¯
            basic_info = f"""
ğŸ“Š è‚¡ç¥¨ä»£ç : {symbol}
ğŸ¢ å…¬å¸åç§°: {info.get('longName', 'N/A')}
ğŸ’° å½“å‰ä»·æ ¼: ${info.get('currentPrice', 'N/A')}
ğŸ“ˆ ä»Šæ—¥æ¶¨è·Œ: {info.get('regularMarketChangePercent', 'N/A')}%
ğŸ† å¸‚å€¼: ${info.get('marketCap', 0):,}
ğŸ“Š å¸‚ç›ˆç‡: {info.get('trailingPE', 'N/A')}
ğŸ¯ 52å‘¨æœ€é«˜: ${info.get('fiftyTwoWeekHigh', 'N/A')}
ğŸ“‰ 52å‘¨æœ€ä½: ${info.get('fiftyTwoWeekLow', 'N/A')}
ğŸ­ è¡Œä¸š: {info.get('industry', 'N/A')}
ğŸŒ æ¿å—: {info.get('sector', 'N/A')}
            """
            
            # æŠ€æœ¯æŒ‡æ ‡
            if not hist.empty:
                current_price = hist['Close'][-1]
                sma_20 = hist['Close'].rolling(window=20).mean()[-1]
                volatility = hist['Close'].pct_change().std() * 100
                
                technical_info = f"""
ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡:
  - 20æ—¥å‡çº¿: ${sma_20:.2f}
  - å½“å‰ä»·æ ¼vså‡çº¿: {'ä¸Šæ–¹' if current_price > sma_20 else 'ä¸‹æ–¹'}
  - æ³¢åŠ¨ç‡: {volatility:.2f}%
                """
            else:
                technical_info = "ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡: æ•°æ®ä¸è¶³"
            
            # å…¬å¸æè¿°
            description = info.get('longBusinessSummary', 'N/A')
            if len(description) > 300:
                description = description[:300] + "..."
            
            return f"{basic_info}\n{technical_info}\n\nğŸ“ å…¬å¸ç®€ä»‹:\n{description}"
            
        except Exception as e:
            return f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}"


# ========== å¤šæ™ºèƒ½ä½“å›¢é˜Ÿ ==========
class ResearchTeam:
    """ç ”ç©¶å›¢é˜Ÿ - å¤šæ™ºèƒ½ä½“åä½œ"""
    
    def __init__(self, model_provider: str = "openai"):
        """
        åˆå§‹åŒ–ç ”ç©¶å›¢é˜Ÿ
        
        Args:
            model_provider: æ¨¡å‹æä¾›å•† ("openai" æˆ– "anthropic")
        """
        # é€‰æ‹©åŸºç¡€æ¨¡å‹
        if model_provider == "anthropic":
            base_model = Claude(id="claude-3-5-sonnet-20241022")
        else:
            base_model = OpenAIChat(id="gpt-4o")
        
        # åˆ›å»ºä¸“é—¨åŒ–çš„æ™ºèƒ½ä½“
        self.web_researcher = Agent(
            name="ç½‘ç»œç ”ç©¶ä¸“å®¶",
            role="è´Ÿè´£æœç´¢å’Œæ”¶é›†ç½‘ç»œä¿¡æ¯",
            model=base_model,
            tools=[
                TavilySearchTool(),
                DuckDuckGoTools(),
            ],
            instructions=[
                "ä¸“æ³¨äºæœç´¢é«˜è´¨é‡ã€æƒå¨çš„ä¿¡æ¯æº",
                "æ€»æ˜¯æä¾›ä¿¡æ¯æ¥æºé“¾æ¥",
                "ä¼˜å…ˆä½¿ç”¨æœ€æ–°çš„ä¿¡æ¯",
                "å¯¹æœç´¢ç»“æœè¿›è¡Œåˆæ­¥ç­›é€‰å’Œæ•´ç†"
            ],
            markdown=True,
        )
        
        self.financial_analyst = Agent(
            name="é‡‘èåˆ†æå¸ˆ", 
            role="è´Ÿè´£é‡‘èæ•°æ®åˆ†æå’Œè‚¡ç¥¨ç ”ç©¶",
            model=base_model,
            tools=[
                EnhancedStockTool(),
                YFinanceTools(
                    stock_price=True,
                    company_info=True,
                    analyst_recommendations=True,
                    company_news=True
                ),
                AdvancedCalculatorTool(),
            ],
            instructions=[
                "æä¾›æ·±åº¦çš„é‡‘èåˆ†æ",
                "ä½¿ç”¨è¡¨æ ¼å±•ç¤ºå…³é”®æ•°æ®",
                "åŒ…å«é£é™©è¯„ä¼°",
                "ç»™å‡ºæ˜ç¡®çš„æŠ•èµ„å»ºè®®"
            ],
            markdown=True,
        )
        
        self.reasoning_expert = Agent(
            name="æ¨ç†åˆ†æä¸“å®¶",
            role="è´Ÿè´£é€»è¾‘æ¨ç†å’Œç»¼åˆåˆ†æ",
            model=base_model,
            tools=[ReasoningTools(add_instructions=True)],
            instructions=[
                "ä½¿ç”¨é€æ­¥æ¨ç†è§£å†³å¤æ‚é—®é¢˜",
                "å±•ç¤ºå®Œæ•´çš„æ€è€ƒè¿‡ç¨‹",
                "ä»å¤šä¸ªè§’åº¦åˆ†æé—®é¢˜", 
                "å¾—å‡ºæœ‰é€»è¾‘æ”¯æ’‘çš„ç»“è®º"
            ],
            markdown=True,
            show_tool_calls=True,
        )
        
        # åˆ›å»ºåä½œå›¢é˜Ÿ
        self.team = Team(
            model=base_model,
            members=[self.web_researcher, self.financial_analyst, self.reasoning_expert],
            instructions=[
                "å›¢é˜Ÿåä½œå®Œæˆå¤æ‚ä»»åŠ¡",
                "æ¯ä¸ªæˆå‘˜å‘æŒ¥è‡ªå·±çš„ä¸“é•¿",
                "æœ€ç»ˆæä¾›å…¨é¢ã€å‡†ç¡®çš„ç­”æ¡ˆ",
                "ä¿æŒé€»è¾‘æ¸…æ™°å’Œç»“æ„åŒ–"
            ],
            show_tool_calls=True,
            markdown=True,
        )
        
        print(f"âœ… Agnoç ”ç©¶å›¢é˜Ÿåˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨{model_provider}æ¨¡å‹")
    
    def research(self, topic: str) -> str:
        """æ‰§è¡Œç ”ç©¶ä»»åŠ¡"""
        return self.team.run(f"è¯·æ·±å…¥ç ”ç©¶: {topic}")


# ========== æ™ºèƒ½å·¥ä½œæµ ==========
class IntelligentWorkflow(Workflow):
    """æ™ºèƒ½å·¥ä½œæµ - ä»»åŠ¡è§„åˆ’å’Œæ‰§è¡Œ"""
    
    def __init__(self, model_provider: str = "openai"):
        super().__init__(name="intelligent_workflow")
        
        # é€‰æ‹©æ¨¡å‹
        if model_provider == "anthropic":
            model = Claude(id="claude-3-5-sonnet-20241022")
        else:
            model = OpenAIChat(id="gpt-4o")
        
        # ä»»åŠ¡åˆ†ç±»å™¨
        self.classifier = Agent(
            name="ä»»åŠ¡åˆ†ç±»å™¨",
            role="åˆ†æå’Œåˆ†ç±»ç”¨æˆ·è¯·æ±‚",
            model=model,
            instructions=[
                "åˆ†æç”¨æˆ·è¯·æ±‚çš„ç±»å‹å’Œå¤æ‚åº¦",
                "å†³å®šæœ€é€‚åˆçš„å¤„ç†æ–¹å¼",
                "æä¾›æ¸…æ™°çš„åˆ†ç±»ç»“æœ"
            ]
        )
        
        # é€šç”¨å¯¹è¯åŠ©æ‰‹
        self.chat_assistant = Agent(
            name="å¯¹è¯åŠ©æ‰‹", 
            role="å¤„ç†æ—¥å¸¸å¯¹è¯å’Œç®€å•é—®ç­”",
            model=model,
            tools=[AdvancedCalculatorTool()],
            instructions=[
                "æä¾›å‹å¥½ã€æœ‰ç”¨çš„å›ç­”",
                "å¯¹äºç®€å•é—®é¢˜ç›´æ¥å›ç­”",
                "å¿…è¦æ—¶ä½¿ç”¨å·¥å…·è¾…åŠ©"
            ]
        )
        
        # ç ”ç©¶å›¢é˜Ÿ
        self.research_team = ResearchTeam(model_provider)
        
        print(f"âœ… æ™ºèƒ½å·¥ä½œæµåˆå§‹åŒ–å®Œæˆ")
    
    def run(self, user_request: str) -> str:
        """æ‰§è¡Œå·¥ä½œæµ"""
        
        # Step 1: ä»»åŠ¡åˆ†ç±»
        classification = self.classifier.run(f"""
        è¯·åˆ†æä»¥ä¸‹ç”¨æˆ·è¯·æ±‚ï¼Œå¹¶åˆ†ç±»ï¼š
        
        ç”¨æˆ·è¯·æ±‚: {user_request}
        
        åˆ†ç±»é€‰é¡¹:
        1. simple_chat - ç®€å•å¯¹è¯ã€é—®å€™ã€åŸºæœ¬é—®ç­”
        2. calculation - æ•°å­¦è®¡ç®—
        3. research - éœ€è¦æœç´¢ä¿¡æ¯çš„ç ”ç©¶ä»»åŠ¡
        4. financial_analysis - é‡‘èã€è‚¡ç¥¨ç›¸å…³åˆ†æ
        5. complex_analysis - éœ€è¦æ·±åº¦åˆ†æå’Œæ¨ç†çš„å¤æ‚ä»»åŠ¡
        
        è¯·åªè¿”å›åˆ†ç±»åç§°ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
        """)
        
        task_type = classification.strip().lower()
        
        # Step 2: æ ¹æ®åˆ†ç±»æ‰§è¡Œç›¸åº”å¤„ç†
        if task_type in ["simple_chat", "calculation"]:
            return self.chat_assistant.run(user_request)
        
        elif task_type in ["research", "financial_analysis", "complex_analysis"]:
            return self.research_team.research(user_request)
        
        else:
            # é»˜è®¤ä½¿ç”¨èŠå¤©åŠ©æ‰‹
            return self.chat_assistant.run(user_request)


# ========== ä¸»è¦Agentç±» ==========
class AgnoAgent:
    """åŸºäºAgnoçš„æ™ºèƒ½åŠ©æ‰‹"""
    
    def __init__(self, model_provider: str = "openai"):
        """
        åˆå§‹åŒ–Agnoæ™ºèƒ½åŠ©æ‰‹
        
        Args:
            model_provider: æ¨¡å‹æä¾›å•† ("openai" æˆ– "anthropic")
        """
        self.model_provider = model_provider
        
        # åˆ›å»ºå·¥ä½œæµ
        self.workflow = IntelligentWorkflow(model_provider)
        
        # ä¼šè¯å†å²
        self.chat_history: Dict[str, List[str]] = {}
        
        print(f"ğŸ‰ Agnoæ™ºèƒ½åŠ©æ‰‹åˆå§‹åŒ–å®Œæˆï¼")
        print(f"ğŸ“ æ¨¡å‹æä¾›å•†: {model_provider}")
        print(f"ğŸ”§ åŠŸèƒ½: å¯¹è¯ã€æœç´¢ã€åˆ†æã€æ¨ç†ã€é‡‘èæ•°æ®")
    
    def chat(self, message: str, session_id: str = "default") -> str:
        """
        ä¸æ™ºèƒ½åŠ©æ‰‹å¯¹è¯
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: ä¼šè¯ID
        
        Returns:
            str: åŠ©æ‰‹å›å¤
        """
        try:
            # ç»´æŠ¤ä¼šè¯å†å²
            if session_id not in self.chat_history:
                self.chat_history[session_id] = []
            
            # è®°å½•ç”¨æˆ·æ¶ˆæ¯
            self.chat_history[session_id].append(f"ç”¨æˆ·: {message}")
            
            # æ‰§è¡Œå·¥ä½œæµå¤„ç†
            response = self.workflow.run(message)
            
            # è®°å½•åŠ©æ‰‹å›å¤
            self.chat_history[session_id].append(f"åŠ©æ‰‹: {response}")
            
            return response
            
        except Exception as e:
            error_msg = f"å¤„ç†å¤±è´¥: {str(e)}"
            print(f"âŒ {error_msg}")
            return error_msg
    
    def get_chat_history(self, session_id: str = "default") -> List[str]:
        """è·å–èŠå¤©å†å²"""
        return self.chat_history.get(session_id, [])
    
    def clear_history(self, session_id: str = "default"):
        """æ¸…é™¤èŠå¤©å†å²"""
        if session_id in self.chat_history:
            del self.chat_history[session_id]
            print(f"âœ… å·²æ¸…é™¤ä¼šè¯ {session_id} çš„å†å²è®°å½•")
    
    def switch_model(self, new_provider: str):
        """åˆ‡æ¢æ¨¡å‹æä¾›å•†"""
        if new_provider in ["openai", "anthropic"]:
            self.model_provider = new_provider
            self.workflow = IntelligentWorkflow(new_provider)
            print(f"âœ… å·²åˆ‡æ¢åˆ° {new_provider} æ¨¡å‹")
        else:
            print("âŒ ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†ï¼Œæ”¯æŒ: openai, anthropic")


# ========== ä½¿ç”¨ç¤ºä¾‹å’Œæ¼”ç¤º ==========
def demo_agno_agent():
    """Agno Agent æ¼”ç¤º"""
    print("\n" + "="*60)
    print("ğŸš€ Agnoæ™ºèƒ½åŠ©æ‰‹æ¼”ç¤º") 
    print("="*60)
    
    # åˆ›å»ºæ™ºèƒ½åŠ©æ‰‹ - å¯ä»¥é€‰æ‹©ä¸åŒæ¨¡å‹
    print("é€‰æ‹©æ¨¡å‹æä¾›å•†ï¼š")
    print("1. OpenAI (gpt-4o)")
    print("2. Anthropic (claude-3-5-sonnet)")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2ï¼Œé»˜è®¤1): ").strip()
    model_provider = "anthropic" if choice == "2" else "openai"
    
    agent = AgnoAgent(model_provider=model_provider)
    
    # æµ‹è¯•åœºæ™¯
    test_cases = [
        {
            "name": "ç®€å•å¯¹è¯",
            "message": "ä½ å¥½ï¼è¯·ä»‹ç»ä¸€ä¸‹ä½ çš„èƒ½åŠ›",
        },
        {
            "name": "æ•°å­¦è®¡ç®—",
            "message": "è®¡ç®—å¤åˆå¢é•¿ç‡ï¼šåˆå€¼100ï¼Œå¹´å¢é•¿ç‡15%ï¼Œ5å¹´åçš„å€¼æ˜¯å¤šå°‘ï¼Ÿ"
        },
        {
            "name": "ä¿¡æ¯ç ”ç©¶", 
            "message": "2024å¹´AIå¤§æ¨¡å‹çš„æœ€æ–°å‘å±•è¶‹åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ"
        },
        {
            "name": "è‚¡ç¥¨åˆ†æ",
            "message": "åˆ†æå¾®è½¯(MSFT)çš„è‚¡ç¥¨æŠ•èµ„ä»·å€¼ï¼ŒåŒ…æ‹¬åŸºæœ¬é¢å’ŒæŠ€æœ¯é¢"
        },
        {
            "name": "å¤æ‚æ¨ç†",
            "message": "å¦‚æœè¦åœ¨2025å¹´å¼€å§‹æŠ•èµ„AIç›¸å…³è‚¡ç¥¨ï¼Œåº”è¯¥è€ƒè™‘å“ªäº›å› ç´ ï¼Ÿè¯·ç»™å‡ºè¯¦ç»†çš„åˆ†ææ¡†æ¶"
        }
    ]
    
    for i, test in enumerate(test_cases, 1):
        print(f"\n{'='*40}")
        print(f"ğŸ“‹ æµ‹è¯• {i}: {test['name']}")
        print(f"{'='*40}")
        print(f"â“ é—®é¢˜: {test['message']}")
        print("\nğŸ’­ å¤„ç†ä¸­...")
        
        # æ‰§è¡Œæµ‹è¯•
        response = agent.chat(test['message'], session_id=f"demo_{i}")
        
        print(f"\nğŸ¤– å›ç­”:")
        print("-" * 40)
        print(response)
        print("-" * 40)
        
        # è¯¢é—®æ˜¯å¦ç»§ç»­
        if i < len(test_cases):
            continue_test = input(f"\nç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•ï¼Ÿ(y/n, é»˜è®¤y): ").strip().lower()
            if continue_test == 'n':
                break
    
    print(f"\nâœ… Agno Agentæ¼”ç¤ºå®Œæˆï¼")
    
    # æ˜¾ç¤ºä¼šè¯å†å²ç¤ºä¾‹
    print(f"\nğŸ“š ä¼šè¯å†å²ç¤ºä¾‹ (æœ€åä¸€ä¸ªä¼šè¯):")
    history = agent.get_chat_history("demo_1")
    for entry in history[-4:]:  # æ˜¾ç¤ºæœ€å4æ¡è®°å½•
        print(f"  {entry[:100]}...")


def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("\n" + "="*60)
    print("ğŸ¯ è¿›å…¥äº¤äº’æ¨¡å¼")
    print("="*60)
    
    # é€‰æ‹©æ¨¡å‹
    print("é€‰æ‹©æ¨¡å‹æä¾›å•†ï¼š")
    print("1. OpenAI (gpt-4o)")  
    print("2. Anthropic (claude-3-5-sonnet)")
    
    choice = input("è¯·è¾“å…¥é€‰æ‹© (1 æˆ– 2ï¼Œé»˜è®¤1): ").strip()
    model_provider = "anthropic" if choice == "2" else "openai"
    
    agent = AgnoAgent(model_provider=model_provider)
    
    print("\nâœ¨ æ™ºèƒ½åŠ©æ‰‹å·²å°±ç»ªï¼è¾“å…¥ 'quit' é€€å‡ºï¼Œ'clear' æ¸…é™¤å†å²")
    print(f"ğŸ’¡ æç¤ºï¼šæˆ‘å¯ä»¥å¸®ä½ æœç´¢ä¿¡æ¯ã€åˆ†ææ•°æ®ã€è®¡ç®—æ•°å­¦é¢˜ã€åˆ†æè‚¡ç¥¨ç­‰")
    
    session_id = "interactive"
    
    while True:
        try:
            user_input = input(f"\nğŸ’¬ ä½ : ").strip()
            
            if user_input.lower() == 'quit':
                print("ğŸ‘‹ å†è§ï¼")
                break
            elif user_input.lower() == 'clear':
                agent.clear_history(session_id)
                continue
            elif user_input.lower() == 'history':
                history = agent.get_chat_history(session_id)
                print("\nğŸ“š å¯¹è¯å†å²:")
                for entry in history:
                    print(f"  {entry}")
                continue
            elif not user_input:
                continue
            
            print(f"\nğŸ¤– åŠ©æ‰‹: æ€è€ƒä¸­...")
            response = agent.chat(user_input, session_id)
            print(f"\nğŸ¤– åŠ©æ‰‹: {response}")
            
        except KeyboardInterrupt:
            print(f"\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"âŒ å‡ºé”™äº†: {str(e)}")


if __name__ == "__main__":
    print("ğŸŠ æ¬¢è¿ä½¿ç”¨Agnoæ™ºèƒ½åŠ©æ‰‹ï¼")
    print("\né€‰æ‹©è¿è¡Œæ¨¡å¼:")
    print("1. æ¼”ç¤ºæ¨¡å¼ (è‡ªåŠ¨è¿è¡Œæµ‹è¯•æ¡ˆä¾‹)")
    print("2. äº¤äº’æ¨¡å¼ (æ‰‹åŠ¨å¯¹è¯)")
    
    mode = input("\nè¯·é€‰æ‹©æ¨¡å¼ (1 æˆ– 2ï¼Œé»˜è®¤1): ").strip()
    
    if mode == "2":
        interactive_mode()
    else:
        demo_agno_agent()
```

---

## 3. ç¯å¢ƒé…ç½®æ–‡ä»¶

### 3.1 .env ç¯å¢ƒå˜é‡æ–‡ä»¶

```bash
# APIå¯†é’¥é…ç½®
OPENAI_API_KEY=sk-your-openai-key-here
ANTHROPIC_API_KEY=sk-ant-your-anthropic-key-here  
TAVILY_API_KEY=tvly-your-tavily-key-here

# å¯é€‰é…ç½®
GROQ_API_KEY=gsk-your-groq-key-here

# Agnoé…ç½®
AGNO_TELEMETRY=false
```

### 3.2 requirements.txt ä¾èµ–æ–‡ä»¶

#### LangGraphç‰ˆæœ¬:
```
langgraph>=0.2.76
langchain-openai>=0.2.0
langchain-community>=0.3.0  
langchain-core>=0.3.0
tavily-python>=0.5.0
duckduckgo-search>=6.0.0
yfinance>=0.2.0
python-dotenv>=1.0.0
pydantic>=2.5.0
typing-extensions>=4.8.0
```

#### Agnoç‰ˆæœ¬:
```
agno>=1.7.7
openai>=1.50.0
anthropic>=0.34.0
tavily-python>=0.5.0
duckduckgo-search>=6.0.0
yfinance>=0.2.0
python-dotenv>=1.0.0
```

---

## 4. è¿è¡Œè¯´æ˜

### 4.1 å¿«é€Ÿå¼€å§‹

1. **å…‹éš†æˆ–åˆ›å»ºé¡¹ç›®ç›®å½•**
```bash
mkdir ai_agents
cd ai_agents
```

2. **åˆ›å»ºç¯å¢ƒå’Œå®‰è£…ä¾èµ–**
```bash
# LangGraphç¯å¢ƒ
python -m venv langgraph_env
source langgraph_env/bin/activate
pip install -r requirements_langgraph.txt

# Agnoç¯å¢ƒ  
python -m venv agno_env
source agno_env/bin/activate
pip install -r requirements_agno.txt
```

3. **é…ç½®ç¯å¢ƒå˜é‡**
```bash
# åˆ›å»º.envæ–‡ä»¶å¹¶æ·»åŠ APIå¯†é’¥
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶æ·»åŠ ä½ çš„APIå¯†é’¥
```

4. **è¿è¡Œç¤ºä¾‹**
```bash
# è¿è¡ŒLangGraphç¤ºä¾‹
python langgraph_agent.py

# è¿è¡ŒAgnoç¤ºä¾‹
python agno_agent.py
```

### 4.2 åŠŸèƒ½ç‰¹æ€§å¯¹æ¯”

| åŠŸèƒ½ç‰¹æ€§ | LangGraph Agent | Agno Agent |
|---------|----------------|------------|
| å¯¹è¯åŠŸèƒ½ | âœ… æ”¯æŒå¤šè½®å¯¹è¯ | âœ… æ”¯æŒå¤šè½®å¯¹è¯ |
| å·¥å…·è°ƒç”¨ | âœ… çµæ´»çš„å·¥å…·ç³»ç»Ÿ | âœ… ä¸°å¯Œçš„é¢„å»ºå·¥å…· |
| å¤šæ­¥æ¨ç† | âœ… å¤æ‚çš„å›¾çŠ¶æ¨ç† | âœ… å†…ç½®æ¨ç†å·¥å…· |
| ä»»åŠ¡è§„åˆ’ | âœ… åŠ¨æ€è®¡åˆ’ç”Ÿæˆ | âœ… æ™ºèƒ½ä½“å›¢é˜Ÿåä½œ |
| æœç´¢é›†æˆ | âœ… å¤šæœç´¢å¼•æ“ | âœ… å¤šæœç´¢å¼•æ“ |
| æ€§èƒ½ | ğŸ”¶ ä¸­ç­‰ | âœ… é«˜æ€§èƒ½ |
| å­¦ä¹ æ›²çº¿ | ğŸ”¶ è¾ƒé™¡å³­ | âœ… ç›¸å¯¹ç®€å• |
| æ¨¡å‹æ”¯æŒ | âœ… å¤šæ¨¡å‹ | âœ… 23+æ¨¡å‹æä¾›å•† |

### 4.3 ä½¿ç”¨å»ºè®®

**é€‰æ‹©LangGraphçš„æƒ…å†µï¼š**
- éœ€è¦å¤æ‚çš„å·¥ä½œæµæ§åˆ¶
- éœ€è¦ç²¾ç»†çš„çŠ¶æ€ç®¡ç†
- éœ€è¦è‡ªå®šä¹‰å¤æ‚çš„æ¨ç†è·¯å¾„
- æœ‰å›¾ç»“æ„åŒ–å¤„ç†éœ€æ±‚

**é€‰æ‹©Agnoçš„æƒ…å†µï¼š**
- éœ€è¦é«˜æ€§èƒ½å’Œä½å»¶è¿Ÿ
- å¸Œæœ›å¿«é€ŸåŸå‹å¼€å‘
- éœ€è¦å¤šæ™ºèƒ½ä½“åä½œ
- å¸Œæœ›ä½¿ç”¨é¢„å»ºç»„ä»¶

---

## 5. æ‰©å±•å’Œå®šåˆ¶

### 5.1 æ·»åŠ æ–°å·¥å…·

**LangGraphä¸­æ·»åŠ å·¥å…·ï¼š**
```python
@tool
def custom_tool(param: str) -> str:
    """è‡ªå®šä¹‰å·¥å…·æè¿°"""
    # å·¥å…·é€»è¾‘
    return "ç»“æœ"

# æ·»åŠ åˆ°å·¥å…·åˆ—è¡¨
tools.append(custom_tool)
```

**Agnoä¸­æ·»åŠ å·¥å…·ï¼š**
```python
class CustomTool(Tool):
    def __init__(self):
        super().__init__(name="custom_tool", description="è‡ªå®šä¹‰å·¥å…·")
    
    def run(self, param: str) -> str:
        # å·¥å…·é€»è¾‘
        return "ç»“æœ"
```

### 5.2 è‡ªå®šä¹‰æ¨ç†æ¨¡å¼

ä¸¤ä¸ªæ¡†æ¶éƒ½æ”¯æŒè‡ªå®šä¹‰æ¨ç†æ¨¡å¼ï¼Œå¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚å®ç°ç‰¹å®šçš„æ¨ç†é€»è¾‘ã€‚

### 5.3 éƒ¨ç½²å»ºè®®

- ä½¿ç”¨Dockerå®¹å™¨åŒ–éƒ¨ç½²
- é…ç½®é€‚å½“çš„èµ„æºé™åˆ¶
- å®ç°è¯·æ±‚ç¼“å­˜æœºåˆ¶
- æ·»åŠ ç›‘æ§å’Œæ—¥å¿—è®°å½•

---

## 6. æ€»ç»“

æœ¬æ–‡æ¡£æä¾›äº†ä¸¤ä¸ªå®Œæ•´ã€å¯è¿è¡Œçš„AI agentå®ç°ï¼Œå±•ç¤ºäº†LangGraphå’ŒAgnoæ¡†æ¶çš„å¼ºå¤§åŠŸèƒ½ã€‚ä¸¤ä¸ªæ¡†æ¶å„æœ‰ä¼˜åŠ¿ï¼Œå¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚é€‰æ‹©ä½¿ç”¨ã€‚ä»£ç åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Šå’Œå®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹ï¼Œä¾¿äºç†è§£å’Œæ‰©å±•ã€‚