"""
Agnoæ¨¡å‹å·¥å‚
ç”¨äºåˆ›å»ºä¸åŒæä¾›å•†çš„æ¨¡å‹å®ä¾‹
"""

from typing import Any, Optional
import os

from agno.models.openai import OpenAIChat
from agno.models.anthropic import Claude

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../'))

from model_config import ModelManager, ModelConfig, ModelProvider

# HTTPæ¨¡å‹é€‚é…å™¨
try:
    sys.path.append(os.path.join(os.path.dirname(__file__), '../../../'))
    from http_agno_adapter import create_http_agno_model
    HTTP_ADAPTER_AVAILABLE = True
except ImportError:
    HTTP_ADAPTER_AVAILABLE = False
    print("âš ï¸ HTTPæ¨¡å‹é€‚é…å™¨ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–")


class DeepSeekChatWrapper(OpenAIChat):
    """DeepSeekèŠå¤©æ¨¡å‹åŒ…è£…å™¨ï¼Œç»§æ‰¿å¹¶é‡å†™OpenAIChat"""
    
    def __init__(self, **kwargs):
        # ç¡®ä¿æ­£ç¡®åˆå§‹åŒ–çˆ¶ç±»
        super().__init__(**kwargs)
        # åœ¨çˆ¶ç±»åˆå§‹åŒ–å®Œæˆåå†åŒ…è£…client
        if hasattr(self, 'client') and self.client:
            self._original_client = self.client
            # é‡å†™clientæ¥æ‹¦æˆªAPIè°ƒç”¨
            self.client = DeepSeekAPIClient(self._original_client)

class DeepSeekAPIClient:
    """DeepSeek APIå®¢æˆ·ç«¯åŒ…è£…å™¨ï¼Œå¤„ç†æ¶ˆæ¯è§’è‰²æ˜ å°„"""
    
    def __init__(self, original_client):
        self.original_client = original_client
        # ä»£ç†æ‰€æœ‰å±æ€§åˆ°åŸå§‹å®¢æˆ·ç«¯
        for attr in dir(original_client):
            if not attr.startswith('_') and attr != 'chat':
                setattr(self, attr, getattr(original_client, attr))
    
    @property
    def chat(self):
        return DeepSeekChatCompletions(self.original_client.chat)
    
    def __getattr__(self, name):
        return getattr(self.original_client, name)

class DeepSeekChatCompletions:
    """å¤„ç†èŠå¤©è¡¥å…¨çš„è§’è‰²æ˜ å°„"""
    
    def __init__(self, original_chat):
        self.original_chat = original_chat
        # ä»£ç†completionså±æ€§
        self.completions = DeepSeekCompletionsWrapper(original_chat.completions)
    
    def __getattr__(self, name):
        return getattr(self.original_chat, name)

class DeepSeekCompletionsWrapper:
    """åŒ…è£…completions.createæ–¹æ³•ä»¥å¤„ç†è§’è‰²æ˜ å°„"""
    
    def __init__(self, original_completions):
        self.original_completions = original_completions
    
    def create(self, messages=None, **kwargs):
        """åˆ›å»ºèŠå¤©è¡¥å…¨ï¼Œå¤„ç†æ¶ˆæ¯è§’è‰²æ˜ å°„"""
        if messages:
            # å¤„ç†æ¶ˆæ¯åˆ—è¡¨ï¼Œæ˜ å°„ä¸æ”¯æŒçš„è§’è‰²
            processed_messages = []
            has_developer_role = False
            
            for msg in messages:
                if isinstance(msg, dict):
                    processed_msg = msg.copy()
                    if 'role' in processed_msg:
                        if processed_msg['role'] == 'developer':
                            processed_msg['role'] = 'system'
                            has_developer_role = True
                        elif processed_msg['role'] not in ['system', 'user', 'assistant', 'tool']:
                            processed_msg['role'] = 'user'
                    processed_messages.append(processed_msg)
                else:
                    processed_messages.append(msg)
            
            # Debugè¾“å‡º
            if has_developer_role:
                print("ğŸ”§ DeepSeek: æ˜ å°„äº†developerè§’è‰²åˆ°systemè§’è‰²")
            
            kwargs['messages'] = processed_messages
        
        return self.original_completions.create(**kwargs)
    
    def __getattr__(self, name):
        return getattr(self.original_completions, name)


class AgnoModelFactory:
    """Agnoæ¡†æ¶æ¨¡å‹å·¥å‚"""
    
    @staticmethod
    def create_model(model_key: str, **kwargs) -> Any:
        """
        åˆ›å»ºæ¨¡å‹å®ä¾‹
        
        Args:
            model_key: æ¨¡å‹é…ç½®é”®å€¼
            **kwargs: é¢å¤–çš„æ¨¡å‹å‚æ•°
            
        Returns:
            æ¨¡å‹å®ä¾‹
        """
        config = ModelManager.get_model_config(model_key)
        if not config:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: {model_key}")
        
        # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        if not ModelManager.is_model_available(model_key):
            raise ValueError(f"æ¨¡å‹ {model_key} ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®")
        
        # åˆå¹¶é…ç½®å‚æ•°
        model_params = {
            'id': config.model_id,
            'temperature': config.temperature,
            'max_tokens': config.max_tokens,
            **kwargs  # å…è®¸è¦†ç›–é»˜è®¤å‚æ•°
        }
        
        # æ ¹æ®æä¾›å•†åˆ›å»ºç›¸åº”çš„æ¨¡å‹å®ä¾‹
        if config.provider == ModelProvider.OPENAI:
            return AgnoModelFactory._create_openai_model(config, model_params)
        
        elif config.provider == ModelProvider.ANTHROPIC:
            return AgnoModelFactory._create_anthropic_model(config, model_params)
        
        elif config.provider == ModelProvider.GROQ:
            return AgnoModelFactory._create_groq_model(config, model_params)
        
        elif config.provider == ModelProvider.OLLAMA:
            return AgnoModelFactory._create_ollama_model(config, model_params)
        
        elif config.provider == ModelProvider.DEEPSEEK:
            return AgnoModelFactory._create_deepseek_model(config, model_params)
        
        elif config.provider == ModelProvider.HTTP:
            return AgnoModelFactory._create_http_model(config, model_params)
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹æä¾›å•†: {config.provider}")
    
    @staticmethod
    def _create_openai_model(config: ModelConfig, params: dict) -> OpenAIChat:
        """åˆ›å»ºOpenAIæ¨¡å‹"""
        # ä½¿ç”¨é…ç½®ä¸­çš„APIå¯†é’¥
        if config.api_key:
            params['api_key'] = config.api_key
        
        return OpenAIChat(**params)
    
    @staticmethod
    def _create_anthropic_model(config: ModelConfig, params: dict) -> Claude:
        """åˆ›å»ºAnthropicæ¨¡å‹"""
        # ä½¿ç”¨é…ç½®ä¸­çš„APIå¯†é’¥
        if config.api_key:
            params['api_key'] = config.api_key
        
        return Claude(**params)
    
    @staticmethod
    def _create_groq_model(config: ModelConfig, params: dict) -> Any:
        """åˆ›å»ºGroqæ¨¡å‹ï¼ˆé€šè¿‡OpenAIå…¼å®¹æ¥å£ï¼‰"""
        try:
            # Groqä½¿ç”¨OpenAIå…¼å®¹çš„æ¥å£
            from agno.models.openai import OpenAIChat
            
            # è®¾ç½®Groqç‰¹å®šå‚æ•°
            groq_params = params.copy()
            groq_params['base_url'] = "https://api.groq.com/openai/v1"
            
            # ä½¿ç”¨é…ç½®ä¸­çš„APIå¯†é’¥
            if config.api_key:
                groq_params['api_key'] = config.api_key
            
            return OpenAIChat(**groq_params)
            
        except ImportError:
            raise ValueError("åˆ›å»ºGroqæ¨¡å‹å¤±è´¥ï¼Œè¯·ç¡®è®¤Agnoç‰ˆæœ¬æ”¯æŒ")
    
    @staticmethod
    def _create_ollama_model(config: ModelConfig, params: dict) -> Any:
        """åˆ›å»ºOllamaæœ¬åœ°æ¨¡å‹"""
        try:
            from agno.models.ollama import Ollama
            
            # è®¾ç½®Ollamaå‚æ•°
            ollama_params = params.copy()
            if config.base_url:
                ollama_params['host'] = config.base_url
            
            # Ollamaä¸éœ€è¦APIå¯†é’¥
            ollama_params.pop('api_key', None)
            
            return Ollama(**ollama_params)
            
        except ImportError:
            # å¦‚æœæ²¡æœ‰Ollamaæ”¯æŒï¼Œå°è¯•é€šè¿‡OpenAIæ¥å£
            print("âš ï¸ æœªæ‰¾åˆ°Ollamaæ¨¡å—ï¼Œå°è¯•é€šè¿‡OpenAIå…¼å®¹æ¥å£è¿æ¥")
            
            ollama_params = params.copy()
            ollama_params['base_url'] = config.base_url or "http://localhost:11434/v1"
            ollama_params['api_key'] = "ollama"  # Ollamaä¸éªŒè¯APIå¯†é’¥
            
            from agno.models.openai import OpenAIChat
            return OpenAIChat(**ollama_params)
    
    @staticmethod
    def _create_deepseek_model(config: ModelConfig, params: dict) -> Any:
        """åˆ›å»ºDeepSeekæ¨¡å‹ï¼ˆé€šè¿‡OpenAIå…¼å®¹æ¥å£ï¼‰"""
        # DeepSeekä½¿ç”¨OpenAIå…¼å®¹çš„æ¥å£
        deepseek_params = params.copy()
        deepseek_params['base_url'] = config.base_url or "https://api.deepseek.com"
        
        # ä½¿ç”¨é…ç½®ä¸­çš„APIå¯†é’¥
        if config.api_key:
            deepseek_params['api_key'] = config.api_key
        
        # ä¸ºDeepSeekæ¨¡å‹æ·»åŠ è§’è‰²æ˜ å°„åŠŸèƒ½
        model = OpenAIChat(**deepseek_params)
        
        # è®¾ç½®è§’è‰²æ˜ å°„
        if not hasattr(model, '_role_map'):
            model._role_map = {
                'developer': 'system',  # æ˜ å°„developerè§’è‰²åˆ°system
                'function': 'assistant',  # æ˜ å°„functionè§’è‰²åˆ°assistant
            }
        
        return model
    
    @staticmethod
    def _create_http_model(config: ModelConfig, params: dict) -> Any:
        """åˆ›å»ºHTTPæ¨¡å‹"""
        if not HTTP_ADAPTER_AVAILABLE:
            raise ValueError("HTTPæ¨¡å‹é€‚é…å™¨ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥ä¾èµ–å®‰è£…")
        
        if not config.base_url:
            raise ValueError(f"HTTPæ¨¡å‹ {config.name} ç¼ºå°‘base_urlé…ç½®")
        
        if not config.api_key:
            raise ValueError(f"HTTPæ¨¡å‹ {config.name} çš„APIå¯†é’¥æœªé…ç½®: {config.api_key_env}")
        
        # æå–å‚æ•°
        http_params = {
            'url': config.base_url,
            'api_key': config.api_key,
            'model_id': config.model_id,
            'vendor': config.vendor or "generic",
            'temperature': params.get('temperature', config.temperature),
            'max_tokens': params.get('max_tokens', config.max_tokens)
        }
        
        # æ·»åŠ è‡ªå®šä¹‰å¤´éƒ¨
        if config.headers:
            http_params['headers'] = config.headers
        
        import logging
        logging.info(f"ğŸŒ åˆ›å»ºHTTPæ¨¡å‹: {config.name} (ä¾›åº”å•†: {config.vendor})")
        logging.info(f"ğŸ“¡ ç«¯ç‚¹: {config.base_url}")
        
        # åˆ›å»ºHTTP Agnoæ¨¡å‹
        return create_http_agno_model(**http_params)
    
    @staticmethod
    def list_supported_models() -> list:
        """è·å–æ”¯æŒçš„æ¨¡å‹åˆ—è¡¨"""
        return ModelManager.list_available_models()
    
    @staticmethod
    def get_available_models() -> dict:
        """è·å–å½“å‰å¯ç”¨çš„æ¨¡å‹"""
        return ModelManager.get_models_by_availability()


# ä¾¿æ·å‡½æ•°
def create_agno_model(model_key: str = "gpt-4o", **kwargs) -> Any:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ›å»ºAgnoæ¨¡å‹å®ä¾‹
    
    Args:
        model_key: æ¨¡å‹é”®å€¼ï¼Œé»˜è®¤gpt-4o
        **kwargs: é¢å¤–å‚æ•°
    
    Returns:
        æ¨¡å‹å®ä¾‹
    """
    return AgnoModelFactory.create_model(model_key, **kwargs)


if __name__ == "__main__":
    # æµ‹è¯•æ¨¡å‹å·¥å‚
    print("ğŸ§ª æµ‹è¯•Agnoæ¨¡å‹å·¥å‚")
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    available = AgnoModelFactory.get_available_models()
    print(f"å¯ç”¨æ¨¡å‹æ•°é‡: {len(available)}")
    
    for key, config in available.items():
        print(f"- {key}: {config.name}")
    
    # æµ‹è¯•åˆ›å»ºæ¨¡å‹ï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨æ¨¡å‹ï¼‰
    if available:
        test_model_key = list(available.keys())[0]
        print(f"\nğŸ”§ æµ‹è¯•åˆ›å»ºæ¨¡å‹: {test_model_key}")
        
        try:
            model = create_agno_model(test_model_key)
            print(f"âœ… æˆåŠŸåˆ›å»ºæ¨¡å‹: {model}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºæ¨¡å‹å¤±è´¥: {e}")
    else:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•")